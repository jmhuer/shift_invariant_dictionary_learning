%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Juan Huerta at 2021-07-23 23:35:48 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{DBLP:journals/corr/DauphinFAG16,
	Archiveprefix = {arXiv},
	Author = {Yann N. Dauphin and Angela Fan and Michael Auli and David Grangier},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/journals/corr/DauphinFAG16.bib},
	Date-Added = {2021-07-23 23:35:02 -0400},
	Date-Modified = {2021-07-23 23:35:02 -0400},
	Eprint = {1612.08083},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:47:58 +0200},
	Title = {Language Modeling with Gated Convolutional Networks},
	Url = {http://arxiv.org/abs/1612.08083},
	Volume = {abs/1612.08083},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1612.08083}}

@misc{kalchbrenner2017neural,
	Archiveprefix = {arXiv},
	Author = {Nal Kalchbrenner and Lasse Espeholt and Karen Simonyan and Aaron van den Oord and Alex Graves and Koray Kavukcuoglu},
	Date-Added = {2021-07-23 23:33:31 -0400},
	Date-Modified = {2021-07-23 23:33:31 -0400},
	Eprint = {1610.10099},
	Primaryclass = {cs.CL},
	Title = {Neural Machine Translation in Linear Time},
	Year = {2017}}

@misc{oord2016wavenet,
	Archiveprefix = {arXiv},
	Author = {Aaron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew Senior and Koray Kavukcuoglu},
	Date-Added = {2021-07-23 23:29:42 -0400},
	Date-Modified = {2021-07-23 23:29:42 -0400},
	Eprint = {1609.03499},
	Primaryclass = {cs.SD},
	Title = {WaveNet: A Generative Model for Raw Audio},
	Year = {2016}}

@article{Dieleman2021,
	Abstract = {Semantically meaningful information content in perceptual signals is usually unevenly distributed. In speech signals for example, there are often many silences, and the speed of pronunciation can vary considerably. In this work, we propose slow autoencoders (SlowAEs) for unsupervised learning of high-level variable-rate discrete representations of sequences, and apply them to speech. We show that the resulting event-based representations automatically grow or shrink depending on the density of salient information in the input signals, while still allowing for faithful signal reconstruction. We develop run-length Transformers (RLTs) for event-based representation modelling and use them to construct language models in the speech domain, which are able to generate grammatical and semantically coherent utterances and continuations.},
	Archiveprefix = {arXiv},
	Arxivid = {2103.06089},
	Author = {Dieleman, Sander and Nash, Charlie and Engel, Jesse and Simonyan, Karen},
	Date-Added = {2021-07-23 23:20:27 -0400},
	Date-Modified = {2021-07-23 23:20:27 -0400},
	Eprint = {2103.06089},
	File = {:Users/juanhuerta/Downloads/2103.06089.pdf:pdf},
	Title = {{Variable-rate discrete representation learning}},
	Url = {http://arxiv.org/abs/2103.06089},
	Year = {2021},
	Bdsk-Url-1 = {http://arxiv.org/abs/2103.06089}}

@article{7439823,
	Author = {Koniusz, Piotr and Yan, Fei and Gosselin, Philippe-Henri and Mikolajczyk, Krystian},
	Date-Added = {2021-07-23 23:08:41 -0400},
	Date-Modified = {2021-07-23 23:08:41 -0400},
	Doi = {10.1109/TPAMI.2016.2545667},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {2},
	Pages = {313-326},
	Title = {Higher-Order Occurrence Pooling for Bags-of-Words: Visual Concept Detection},
	Volume = {39},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2016.2545667}}

@article{Peyre2009,
	Author = {Peyr{\'e}, Gabriel},
	Date-Added = {2021-07-23 23:03:48 -0400},
	Date-Modified = {2021-07-23 23:04:58 -0400},
	File = {:Users/juanhuerta/Downloads/08-JMIV-Peyre-SparseTextures.pdf:pdf},
	Number = {1},
	Pages = {17--31},
	Title = {Sparse Modeling of Textures},
	Volume = {34},
	Year = {2009}}

@article{Ramrez2010ClassificationAC,
	Author = {I. Ram{\'\i}rez and P. Sprechmann and G. Sapiro},
	Date-Added = {2021-07-21 23:30:12 -0400},
	Date-Modified = {2021-07-21 23:30:12 -0400},
	Journal = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	Pages = {3501-3508},
	Title = {Classification and clustering via dictionary learning with structured incoherence and shared features},
	Year = {2010}}

@article{Koniusz2017,
	Abstract = {In object recognition, the Bag-of-Words model assumes: i) extraction of local descriptors from images, ii) embedding the descriptors by a coder to a given visual vocabulary space which results in mid-level features, iii) extracting statistics from mid-level features with a pooling operator that aggregates occurrences of visual words in images into signatures, which we refer to as First-order Occurrence Pooling. This paper investigates higher-order pooling that aggregates over co-occurrences of visual words. We derive Bag-of-Words with Higher-order Occurrence Pooling based on linearisation of Minor Polynomial Kernel, and extend this model to work with various pooling operators. This approach is then effectively used for fusion of various descriptor types. Moreover, we introduce Higher-order Occurrence Pooling performed directly on local image descriptors as well as a novel pooling operator that reduces the correlation in the image signatures. Finally, First-, Second-, and Third-order Occurrence Pooling are evaluated given various coders and pooling operators on several widely used benchmarks. The proposed methods are compared to other approaches such as Fisher Vector Encoding and demonstrate improved results.},
	Author = {Koniusz, Piotr and Yan, Fei and Gosselin, Philippe Henri and Mikolajczyk, Krystian},
	Date-Added = {2021-07-21 23:18:16 -0400},
	Date-Modified = {2021-07-21 23:18:16 -0400},
	Doi = {10.1109/TPAMI.2016.2545667},
	File = {:Users/juanhuerta/Downloads/koniusz16pami.pdf:pdf},
	Issn = {01628828},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Keywords = {Bag-of-words,co-occurrence,first-order,mid-level features,pooling operator,second-order,sparse coding},
	Mendeley-Groups = {SIDL},
	Number = {2},
	Pages = {313--326},
	Pmid = {27019477},
	Title = {{Higher-Order Occurrence Pooling for Bags-of-Words: Visual Concept Detection}},
	Volume = {39},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2016.2545667}}

@inproceedings{groove2019,
	Author = {Jon Gillick and Adam Roberts and Jesse Engel and Douglas Eck and David Bamman},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Date-Added = {2021-07-21 22:48:52 -0400},
	Date-Modified = {2021-07-21 22:48:52 -0400},
	Title = {Learning to Groove with Inverse Sequence Transformations},
	Year = {2019}}

@inproceedings{hawthorne2018enabling,
	Author = {Curtis Hawthorne and Andriy Stasyuk and Adam Roberts and Ian Simon and Cheng-Zhi Anna Huang and Sander Dieleman and Erich Elsen and Jesse Engel and Douglas Eck},
	Booktitle = {International Conference on Learning Representations},
	Date-Added = {2021-07-21 22:30:19 -0400},
	Date-Modified = {2021-07-21 22:30:19 -0400},
	Title = {Enabling Factorized Piano Music Modeling and Generation with the {MAESTRO} Dataset},
	Url = {https://openreview.net/forum?id=r1lYRjC9F7},
	Year = {2019},
	Bdsk-Url-1 = {https://openreview.net/forum?id=r1lYRjC9F7},
	Bdsk-File-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAoLi4vLi4vLi4vLi4vRG93bmxvYWRzL3BrcGFtaTJlLXBldGVyLnBkZk8RAWIAAAAAAWIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAAAAAABCRAAB/////xJwa3BhbWkyZS1wZXRlci5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////AAAAAAAAAAAAAAAAAAQAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAC8vOlVzZXJzOmp1YW5odWVydGE6RG93bmxvYWRzOnBrcGFtaTJlLXBldGVyLnBkZgAADgAmABIAcABrAHAAYQBtAGkAMgBlAC0AcABlAHQAZQByAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvanVhbmh1ZXJ0YS9Eb3dubG9hZHMvcGtwYW1pMmUtcGV0ZXIucGRmAAATAAEvAAAVAAIAEf//AAAACAANABoAJABPAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAbU=}}

@inproceedings{GodfriedToussaint2004,
	Author = {{Godfried Toussaint}},
	Booktitle = {ISMIR},
	Title = {{A Comparison of Rhythmic Similarity Measures.}},
	Year = {2004}}

@inproceedings{SrinivasM2014,
	Author = {{Srinivas M} and {Roy D} and {Mohan CK}},
	Booktitle = {International Joint Conference on Neural Networks (IJCNN)},
	Pages = {1937--1941},
	Title = {{Music genre classification using on-line dictionary learning.}},
	Year = {2014}}

@article{YigitOktar2020,
	Author = {{Yigit Oktar} and {Mehmet Turkan}},
	Journal = {arXiv preprint arXiv:2006.08321},
	Title = {{On the Preservation of Spatio-temporal Information in Machine Learning Applications.}},
	Year = {2020}}

@article{ShaojieBai2018,
	Author = {{Shaojie Bai} and {J. Zico Kolter} and {Vladlen Koltun}},
	Journal = {arXiv preprint arXiv:1803.01271},
	Title = {{An empirical evaluation of generic convolutional and recurrent networks for sequence modeling.}},
	Year = {2018}}

@article{GaetanHadjeres2017,
	Author = {{Ga{\"{e}}tan Hadjeres} and {Frank Nielsen}},
	Journal = {arXiv preprint arXiv:1709.00740},
	Title = {{Deep rank-based transposition-invariant distances on musical sequences}},
	Year = {2017}}

@inproceedings{JiangJunyan2020,
	Author = {{Jiang Junyan} and {Gus Xia} and {Taylor Berg-Kirkpatrick}},
	Booktitle = {Proceedings of the 1st workshop on nlp for music and audio (nlp4musa)},
	Pages = {1--5},
	Title = {{Discovering Music Relations with Sequential Attention}},
	Year = {2020}}

@article{Costantini2013,
	Abstract = {Music transcription consists in transforming the musical content of audio data into a symbolic representation. The objective of this study is to investigate a transcription system for polyphonic piano. The proposed method focuses on temporal musical structures, note events and their main characteristics: the attack instant and the pitch. Onset detection exploits a time-frequency representation of the audio signal. Feature extraction is based on Sparse Nonnegative Matrix Factorization (SNMF) and Constant Q Transform (CQT), while note classification is based on Support Vector Machines (SVMs). Finally, to validate our method, we present a collection of experiments using a wide number of musical pieces of heterogeneous styles.},
	Author = {Costantini, Giovanni and Todisco, Massimiliano and Perfetti, Renzo},
	Issn = {17905052},
	Journal = {WSEAS Transactions on Signal Processing},
	Number = {3},
	Title = {{NMF based dictionary learning for automatic transcription of polyphonic piano music}},
	Volume = {9},
	Year = {2013}}

@inproceedings{Blumensath2006,
	Abstract = {Redundancy reduction has been proposed as the main computational process in the primary sensory pathways in the mammalian brain. This idea has led to the development of sparse coding techniques, which are exploited in this article to extract salient structure from musical signals. In particular, we use a sparse coding formulation within a generative model that explicitly enforces shift-invariance. Previous work has applied these methods to relatively small problem sizes. In this paper, we present a subset selection step to reduce the computational complexity of these methods, which then enables us to use the sparse coding approach for many real world applications. We demonstrate the algorithm's potential on two tasks in music analysis: the extraction of individual notes from polyphonic piano music and single-channel blind source separation. {\textcopyright} 2006 IEEE.},
	Author = {Blumensath, Thomas and Davies, Mike},
	Booktitle = {IEEE Transactions on Audio, Speech and Language Processing},
	Doi = {10.1109/TSA.2005.860346},
	Issn = {15587916},
	Number = {1},
	Title = {{Sparse and shift-invariant representations of music}},
	Volume = {14},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1109/TSA.2005.860346}}

@article{Cogliati2016,
	Abstract = {This paper presents a novel approach to automatic transcription of piano music in a context-dependent setting. This approach employs convolutional sparse coding to approximate the music waveform as the summation of piano note waveforms (dictionary elements) convolved with their temporal activations (onset transcription). The piano note waveforms are pre-recorded for the specific piano to be transcribed in the specific environment. During transcription, the note waveforms are fixed and their temporal activations are estimated and post-processed to obtain the pitch and onset transcription. This approach works in the time domain, models temporal evolution of piano notes, and estimates pitches and onsets simultaneously in the same framework. Experiments show that it significantly outperforms a state-of-the-art music transcription method trained in the same context-dependent setting, in both transcription accuracy and time precision, in various scenarios including synthetic, anechoic, noisy, and reverberant environments.},
	Author = {Cogliati, Andrea and Duan, Zhiyao and Wohlberg, Brendt},
	Doi = {10.1109/TASLP.2016.2598305},
	Issn = {23299290},
	Journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	Number = {12},
	Title = {{Context-Dependent Piano Music Transcription with Convolutional Sparse Coding}},
	Volume = {24},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1109/TASLP.2016.2598305}}

@inproceedings{Srinivas2014,
	Abstract = {The field of music and speech classification is quite mature with researchers having settled on the approximate best discriminative representation. In this regard, Zubair et al. showed the use of sparse coefficients alongwith SVM to classify audio signals as music or speech to get a near-perfect classification. In the proposed method, we go one step further, instead of using the sparse coefficients with another classifier they are directly used in a dictionary which is learned using on-line dictionary learning for music-speech classification. This approach removes the redundancy of using a separate classifier but also produces complete discrimination of music and speech on the GTZAN music/speech dataset. Moreover, instead of the high-dimensional feature vector space which inherently leads to high computation time and complicated decision boundary calculation on the part of SVM, the restricted dictionary size with limited computation serves the same purpose.},
	Author = {Srinivas, M. and Roy, Debaditya and {Krishna Mohan}, C.},
	Booktitle = {International Conference on Digital Signal Processing, DSP},
	Doi = {10.1109/ICDSP.2014.6900749},
	Title = {{Learning sparse dictionaries for music and speech classification}},
	Volume = {2014-January},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICDSP.2014.6900749}}

@inproceedings{Tjoa2010,
	Abstract = {Dictionary learning through matrix factorization has become widely popular for performing music transcription and source separation. These methods learn a concise set of dictionary atoms which represent spectrograms of musical objects. However, there is no guarantee that the atoms learned will be perceptually meaningful, particularly when there exists significant spectral and temporal overlap among the musical sources. In this paper, we propose a novel dictionary learning method that imposes additional harmonic constraints upon the atoms of the learned dictionary while allowing the dictionary size to grow appropriately during the learning procedure. When there is significant spectral-temporal overlap among the musical sources, our method outperforms popular existing matrix factorization methods as measured by the recall and precision of learned dictionary atoms. {\textcopyright}2010 IEEE.},
	Author = {Tjoa, Steven K. and Stamm, Matthew C. and Lin, W. Sabrina and Liu, K. J.Ray},
	Booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	Doi = {10.1109/ICASSP.2010.5495773},
	Issn = {15206149},
	Title = {{Harmonic variable-size dictionary learning for music source separation}},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICASSP.2010.5495773}}

@article{Benetos2013,
	Abstract = {In this paper, we propose an efficient model for automatic transcription of polyphonic music. The model extends the shift-invariant probabilistic latent component analysis method and uses pre-extracted and pre-shifted note templates from multiple instruments. Thus, the pro- posed system can efficiently transcribe polyphonic music, while taking into account tuning deviations and frequency modulations. Additional system improvements utilising massive parallel computations with GPUs result in a system performing much faster than real-time. Experimental results using several datasets show that the proposed system can success- fully transcribe polyphonic music, outperforming several state-of-the-art approaches, and is over 140 times faster compared to a standard shift- invariant transcription model.},
	Author = {Benetos, Emmanouil and Cherla, Srikanth and Weyde, Tillman},
	Journal = {Proceedings of the 6th International Workshop on Machine Learning and Music},
	Title = {{An Effcient Shift-Invariant Model for Polyphonic Music Transcription}},
	Year = {2013}}

@inproceedings{Nuanain2015,
	Abstract = {Composing drum patterns and musically developing them through repetition and variation is a typical task in electronic music production. We propose a system that, given an input pattern, automatically creates related patterns using a genetic algorithm. Two distance measures (the Hamming distance and directed-swap distance) that relate to rhythmic similarity are shown to derive usable fitness functions for the algorithm. A software instrument in the Max for Live environment presents how this can be used in real musical applications. Finally, a user survey was carried out to examine and compare the effectiveness of the fitness metrics in determining rhythmic similarity as well as the usefulness of the instrument for musical creation.},
	Author = {Nuan{\'{a}}in, C{\'{a}}rthach and Herrera, Perfecto and Jord{\`{a}}, Sergi},
	Booktitle = {Proceedings of the 12th International Conference in Sound and Music Computing, SMC 2015},
	Title = {{Target-based rhythmic pattern generation and variation with genetic algorithms}},
	Year = {2015}}

@inproceedings{Vogl2017,
	Abstract = {An important part of electronic dance music (EDM) is the so-called beat. It is defined by the drum track of the piece and is a style defining element. While producing EDM, creating the drum track tends to be delicate, yet labor intensive work. In this work we present a touch-interface-based prototype with the goal to simplify this task. The prototype aims at supporting musicians to create rhythmic patterns in the context of EDM production and live performances. Starting with a seed pattern which is provided by the user, a list of variations with varying degree of deviation from the seed pattern is generated. The interface provides simple ways to enter, edit, visualize and browse through the patterns. Variations are generated by means of an artificial neural network which is trained on a database of drum rhythm patterns extracted from a commercial drum loop library. To evaluate the user interface and pattern generation quality a user study with experts in EDM production was conducted. It was found that participants responded positively to the user interface and the quality of the generated patterns. Furthermore, the experts consider the prototype helpful for both studio production situations and live performances.},
	Author = {Vogl, Richard and Knees, Peter},
	Booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
	Title = {{An Intelligent Drum Machine for Electronic Dance Music Production and Performance}},
	Year = {2017}}

@inproceedings{Lattner2019,
	Abstract = {Spurred by the potential of deep learning, computational music generation has gained renewed academic interest. A crucial issue in music generation is that of user control, especially in scenarios where the music generation process is conditioned on existing musical material. Here we propose a model for conditional kick drum track generation that takes existing musical material as input, in addition to a lowdimensional code that encodes the desired relation between the existing material and the new material to be generated. These relational codes are learned in an unsupervised manner from a music dataset. We show that codes can be sampled to create a variety of musically plausible kick drum tracks and that the model can be used to transfer kick drum patterns from one song to another. Lastly, we demonstrate that the learned codes are largely invariant to tempo and time-shift.},
	Author = {Lattner, Stefan and Grachten, Maarten},
	Booktitle = {IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
	Doi = {10.1109/WASPAA.2019.8937261},
	Issn = {19471629},
	Title = {{High-level control of drum track generation using learned patterns of rhythmic interaction}},
	Volume = {2019-October},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1109/WASPAA.2019.8937261}}

@inproceedings{Srinivas2014a,
	Abstract = {In this paper, an approach for music genre classification based on sparse representation using MARSYAS features is proposed. The MARSYAS feature descriptor consisting of timbral texture, pitch and beat related features is used for the classification of music genre. On-line Dictionary Learning (ODL) is used to achieve sparse representation of the features for developing dictionaries for each musical genre. We demonstrate the efficacy of the proposed framework on the Latin Music Database (LMD) consisting of over 3000 tracks spanning 10 genres namely Ax{\'{e}}, Bachata, Bolero, Forr{\'{o}}, Ga{\'{u}}cha, Merengue, Pagode, Salsa, Sertaneja and Tango.},
	Author = {Srinivas, M. and Roy, Debaditya and Mohan, C. Krishna},
	Booktitle = {Proceedings of the International Joint Conference on Neural Networks},
	Doi = {10.1109/IJCNN.2014.6889516},
	Title = {{Music genre classification using On-line Dictionary Learning}},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2014.6889516}}

@inproceedings{Lewicki1999,
	Abstract = {A common way to represent a time series is to divide it into short-duration blocks, each of which is then represented by a set of basis functions. A limitation of this approach, however, is that the temporal alignment of the basis functions with the underlying structure in the time series is arbitrary. We present an algorithm for encoding a time series that does not require blocking the data. The algorithm finds an efficient representation by inferring the best temporal positions for functions in a kernel basis. These can have arbitrary temporal extent and are not constrained to be orthogonal. This allows the model to capture structure in the signal that may occur at arbitrary temporal positions and preserves the relative temporal structure of underlying events. The model is shown to be equivalent to a very sparse and highly overcomplete basis. Under this model, the mapping from the data to the representation is nonlinear, but can be computed efficiently. This form also allows the use of existing methods for adapting the basis itself to data. This approach is applied to speech data and results in a shift invariant, spike-like representation that resembles coding in the cochlear nerve.},
	Author = {Lewicki, Michael S. and Sejnowski, Terrence J.},
	Booktitle = {Advances in Neural Information Processing Systems},
	Issn = {10495258},
	Title = {{Coding time-varying signals using sparse, shift-invariant representations}},
	Year = {1999}}

@article{Velankar2017,
	Abstract = {Music pattern recognition for different application in content based music information retrieval (MIR) has been a research topic for MIR community since almost a decade. Research is continued for various applications such as automatic music transcription, genre or instrument identification, music classification, mood extraction, music recommendation etc. Music is a rich multidimensional audio signal posing serious research challenge. This paper covers different pattern recognition techniques used for music analysis. Feature engineering for musical features with different level of abstraction using domain experts helps in achieving better results. Different feature learning techniques are applied to train the machine to recognize patterns and various computational proximity measures are used for matching. A detail literature survey of pattern recognition for computational music is presented. Future direction describes novel trends such as deep learning in the domain of computational musicology.},
	Author = {Velankar, Makarand and Kulkarni, Parag},
	Journal = {Frontiers for research in speech and music, At NIT, Rourkela},
	Number = {December 2017},
	Title = {{Pattern Recognition for Computational Music}},
	Year = {2017}}

@inproceedings{Bristow2013,
	Abstract = {Sparse coding has become an increasingly popular method in learning and vision for a variety of classification, reconstruction and coding tasks. The canonical approach intrinsically assumes independence between observations during learning. For many natural signals however, sparse coding is applied to sub-elements ( i.e. patches) of the signal, where such an assumption is invalid. Convolutional sparse coding explicitly models local interactions through the convolution operator, however the resulting optimization problem is considerably more complex than traditional sparse coding. In this paper, we draw upon ideas from signal processing and Augmented Lagrange Methods (ALMs) to produce a fast algorithm with globally optimal sub problems and super-linear convergence. {\textcopyright} 2013 IEEE.},
	Author = {Bristow, Hilton and Eriksson, Anders and Lucey, Simon},
	Booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	Doi = {10.1109/CVPR.2013.57},
	Issn = {10636919},
	Title = {{Fast convolutional sparse coding}},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2013.57}}

@inproceedings{Jas2017,
	Abstract = {Neural time-series data contain a wide variety of prototypical signal waveforms (atoms) that are of significant importance in clinical and cognitive research. One of the goals for analyzing such data is hence to extract such 'shift-invariant' atoms. Even though some success has been reported with existing algorithms, they are limited in applicability due to their heuristic nature. Moreover, they are often vulnerable to artifacts and impulsive noise, which are typically present in raw neural recordings. In this study, we address these issues and propose a novel probabilistic convolutional sparse coding (CSC) model for learning shift-invariant atoms from raw neural signals containing potentially severe artifacts. In the core of our model, which we call $\alpha$CSC, lies a family of heavy-tailed distributions called $\alpha$-stable distributions. We develop a novel, computationally efficient Monte Carlo expectation-maximization algorithm for inference. The maximization step boils down to a weighted CSC problem, for which we develop a computationally efficient optimization algorithm. Our results show that the proposed algorithm achieves state-of-the-art convergence speeds. Besides, $\alpha$CSC is significantly more robust to artifacts when compared to three competing algorithms: it can extract spike bursts, oscillations, and even reveal more subtle phenomena such as cross-frequency coupling when applied to noisy neural time series.},
	Author = {Jas, Mainak and {La Tour}, Tom Dupr{\'{e}} and {\c S}im{\c s}ekli, Umut and Gramfort, Alexandre},
	Booktitle = {Advances in Neural Information Processing Systems},
	Issn = {10495258},
	Title = {{Learning the morphology of brain signals using alpha-stable convolutional sparse coding}},
	Volume = {2017-December},
	Year = {2017}}

@inproceedings{LaTour2018,
	Abstract = {Frequency-specific patterns of neural activity are traditionally interpreted as sustained rhythmic oscillations, and related to cognitive mechanisms such as attention, high level visual processing or motor control. While alpha waves (8-12 Hz) are known to closely resemble short sinusoids, and thus are revealed by Fourier analysis or wavelet transforms, there is an evolving debate that electromagnetic neural signals are composed of more complex waveforms that cannot be analyzed by linear filters and traditional signal representations. In this paper, we propose to learn dedicated representations of such recordings using a multivariate convolutional sparse coding (CSC) algorithm. Applied to electroencephalography (EEG) or magnetoencephalography (MEG) data, this method is able to learn not only prototypical temporal waveforms, but also associated spatial patterns so their origin can be localized in the brain. Our algorithm is based on alternated minimization and a greedy coordinate descent solver that leads to state-of-the-art running time on long time series. To demonstrate the implications of this method, we apply it to MEG data and show that it is able to recover biological artifacts. More remarkably, our approach also reveals the presence of non-sinusoidal mu-shaped patterns, along with their topographic maps related to the somatosensory cortex.},
	Author = {{La Tour}, Tom Dupr{\'{e}} and Moreau, Thomas and Jas, Mainak and Gramfort, Alexandre},
	Booktitle = {Advances in Neural Information Processing Systems},
	Issn = {10495258},
	Title = {{Multivariate convolutional sparse coding for electromagnetic brain signals}},
	Volume = {2018-December},
	Year = {2018}}

@inproceedings{Rangamani2018,
	Abstract = {In this work we study the landscape of squared loss of an Autoencoder when the data generative model is that of 'Sparse Coding'/'Dictionary Learning'. The neural net considered is an $\backslash$mathbb{\{}R{\}}{\^{}}{\{}n{\}}$\backslash$rightarrow $\backslash$mathbb{\{}R{\}}{\^{}}{\{}n{\}} mapping and has a single ReLU activation layer of size h {\textgreater} n. The net has access to vectors y$\backslash$in $\backslash$mathbb{\{}R{\}}{\^{}}{\{}n{\}} obtained as y=A{\^{}}{\{}$\backslash$ast{\}}x{\^{}}{\{}$\backslash$ast{\}} where x{\^{}}{\{}$\backslash$ast{\}}$\backslash$in $\backslash$mathbb{\{}R{\}}{\^{}}{\{}h{\}} are sparse high dimensional vectors and A{\^{}}{\{}$\backslash$ast{\}}$\backslash$in $\backslash$mathbb{\{}R{\}}{\^{}}{\{}n$\backslash$times h{\}} is an overcomplete incoherent matrix. Under very mild distributional assumptions on x{\^{}}{\{}$\backslash$ast{\}}, we prove that the norm of the expected gradient of the squared loss function is asymptotically (in sparse code dimension) negligible for all points in a small neighborhood of A{\^{}}{\{}$\backslash$ast{\}}. This is supported with experimental evidence using synthetic data. We conduct experiments to suggest that A{\^{}}{\{}$\backslash$ast{\}} sits at the bottom of a well in the landscape and we also give experiments showing that gradient descent on this loss function gets columnwise very close to the original dictionary even with far enough initialization. Along the way we prove that a layer of ReLU gates can be set up to automatically recover the support of the sparse codes. Since this property holds independent of the loss function we believe that it could be of independent interest. A full version of this paper is accessible at: https://arxiv.org/abs/1708.03735},
	Author = {Rangamani, Akshay and Mukherjee, Anirbit and Basu, Amitabh and Arora, Ashish and Ganapathi, Tejaswini and Chin, Sang and Tran, Trac D.},
	Booktitle = {IEEE International Symposium on Information Theory - Proceedings},
	Doi = {10.1109/ISIT.2018.8437533},
	Issn = {21578095},
	Title = {{Sparse Coding and Autoencoders}},
	Volume = {2018-June},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISIT.2018.8437533}}

@article{Garcia-Cardona2018,
	Abstract = {Convolutional sparse representations are a form of sparse representation with a dictionary that has a structure that is equivalent to convolution with a set of linear filters. While effective algorithms have recently been developed for the convolutional sparse coding problem, the corresponding dictionary learning problem is substantially more challenging. Furthermore, although a number of different approaches have been proposed, the absence of thorough comparisons between them makes it difficult to determine which of them represents the current state of the art. The present work both addresses this deficiency and proposes some new approaches that outperform existing ones in certain contexts. A thorough set of performance comparisons indicates a very wide range of performance differences among the existing and proposed methods, and clearly identifies those that are the most effective.},
	Author = {Garcia-Cardona, Cristina and Wohlberg, Brendt},
	Doi = {10.1109/tci.2018.2840334},
	Issn = {2573-0436},
	Journal = {IEEE Transactions on Computational Imaging},
	Number = {3},
	Title = {{Convolutional Dictionary Learning: A Comparative Review and New Algorithms}},
	Volume = {4},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/tci.2018.2840334}}

@inproceedings{Roberts2018,
	Abstract = {The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the "posterior collapse" problem which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a "flat" baseline model. An implementation of our "MusicVAE" is available online.2.},
	Author = {Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne, Curtis and Eck, Douglas},
	Booktitle = {35th International Conference on Machine Learning, ICML 2018},
	Title = {{A hierarchical latent vector model for learning long-term structure in music}},
	Volume = {10},
	Year = {2018}}

@inproceedings{Walder2018,
	Abstract = {We present a neural sequence model designed specifically for symbolic music. The model is based on a learned edit distance mechanism which generalises a classic recursion from computer science, leading to a neural dynamic program. Repeated motifs are detected by learning the transformations between them. We represent the arising computational dependencies using a novel data structure, the edit tree; this perspective suggests natural approximations which afford the scaling up of our otherwise cubic time algorithm. We demonstrate our model on real and synthetic data; in all cases it out-performs a strong stacked long short-term memory benchmark. Copyright 2018 by the author(s).},
	Author = {Walder, Christian J. and Kim, Dongwoo},
	Booktitle = {35th International Conference on Machine Learning, ICML 2018},
	Title = {{Neural dynamic programming for musical self similarity}},
	Volume = {11},
	Year = {2018}}

@inproceedings{Zheng2016,
	Abstract = {Shift-invariant dictionary learning (SIDL) refers to the problem of discovering a set of latent basis vectors (the dictionary) that captures informative local patterns at different locations of the input sequences, and a sparse coding for each sequence as a linear combination of the latent basis elements. It differs from conventional dictionary learning and sparse coding where the latent basis has the same dimension as the input vectors, where the focus is on global patterns instead of shift-invariant local patterns. Unsupervised discovery of shift-invariant dictionary and the corresponding sparse coding has been an open challenge as the number of candidate local patterns is extremely large, and the number of possible linear combinations of such local patterns is even more so. In this paper we propose a new framework for unsupervised discovery of both the shift-invariant basis and the sparse coding of input data, with efficient algorithms for tractable optimization. Empirical evaluations on multiple time series data sets demonstrate the effectiveness and efficiency of the proposed method.},
	Author = {Zheng, Guoqing and Yang, Yiming and Carbonell, Jaime},
	Booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	Doi = {10.1145/2939672.2939824},
	Title = {{Efficient shift-invariant dictionary learning}},
	Volume = {13-17-August-2016},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1145/2939672.2939824}}

@inproceedings{Grosse2007,
	Abstract = {Sparse coding is an unsupervised learning algorithm that learns a succinct high-level representation of the inputs given only unlabeled data; it represents each input as a sparse linear combination of a set of basis functions. Originally applied to modeling the human visual cortex, sparse coding has also been shown to be useful for self-taught learning, in which the goal is to solve a supervised classification task given access to additional unlabeled data drawn from different classes than that in the supervised learning problem. Shift-invariant sparse coding (SISC) is an extension of sparse coding which reconstructs a (usually time-series) input using all of the basis functions in all possible shifts. In this paper, we present an efficient algorithm for learning SISC bases. Our method is based on iteratively solving two large convex optimization problems: The first, which computes the linear coefficients, is an L1-regularized linear least squares problem with potentially hundreds of thousands of variables. Existing methods typically use a heuristic to select a small subset of the variables to optimize, but we present a way to efficiently compute the exact solution. The second, which solves for bases, is a constrained linear least squares problem. By optimizing over complex-valued variables in the Fourier domain, we reduce the coupling between the different variables, allowing the problem to be solved efficiently. We show that SISC's learned high-level representations of speech and music provide useful features for classification tasks within those domains. When applied to classification, under certain conditions the learned features outperform state of the art spectral and cep-stral features.},
	Author = {Grosse, Roger and Raina, Rajat and Kwong, Helen and Ng, Andrew Y.},
	Booktitle = {Proceedings of the 23rd Conference on Uncertainty in Artificial Intelligence, UAI 2007},
	Title = {{Shift-invariant sparse coding for audio classification}},
	Year = {2007}}
