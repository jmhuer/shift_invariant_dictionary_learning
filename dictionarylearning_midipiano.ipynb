{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Super_Piano_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/shift_invariant_dictionary_learning/blob/main/dictionarylearning_midipiano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9opKSK2RSDRg"
      },
      "source": [
        "# Set up enviroment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hD19W0hSCP"
      },
      "source": [
        "###Setup Environment and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paYvoZHihtux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "outputId": "b6085269-7b92-422e-8ac5-fdb3ecade36d"
      },
      "source": [
        "#@title Clone/Install all dependencies\n",
        "!git clone https://github.com/jmhuer/shift_invariant_dictionary_learning\n",
        "# !git clone https://github.com/asigalov61/MusicTransformer-Pytorch\n",
        "!pip install tqdm\n",
        "!pip install progress\n",
        "!pip install pretty-midi\n",
        "!pip install pypianoroll\n",
        "!pip install matplotlib\n",
        "!pip install librosa\n",
        "!pip install scipy\n",
        "!pip install pillow\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install mir_eval\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 /content/font.sf2\n",
        "\n",
        "%cd /content/shift_invariant_dictionary_learning/maestro"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'shift_invariant_dictionary_learning' already exists and is not an empty directory.\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: progress in /usr/local/lib/python3.7/dist-packages (1.5)\n",
            "Requirement already satisfied: pretty-midi in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.2.10)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi) (1.15.0)\n",
            "Requirement already satisfied: pypianoroll in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.19.5)\n",
            "Requirement already satisfied: pretty-midi>=0.2.8 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (0.2.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.7/dist-packages (from pypianoroll) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5->pypianoroll) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.5->pypianoroll) (1.15.0)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->pypianoroll) (1.2.10)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fluidsynth is already the newest version (1.1.9-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: midi2audio in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: mir_eval in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "/content/shift_invariant_dictionary_learning/maestro\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM71tUPVfffi",
        "cellView": "code"
      },
      "source": [
        "#@title Import all needed modules\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "# For plotting\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "#%matplotlib inline\n",
        "#matplotlib.get_backend()\n",
        "import mir_eval.display\n",
        "import librosa\n",
        "import librosa.display\n",
        "# For rendering output audio\n",
        "import pretty_midi\n",
        "from midi2audio import FluidSynth\n",
        "from google.colab import output\n",
        "from IPython.display import display, Javascript, HTML, Audio"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gd-O5LZyJGD"
      },
      "source": [
        "#Option 1: MAESTRO DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bGqw8o6oxUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "code",
        "outputId": "72e50bab-9882-42b8-c10e-df7169836161"
      },
      "source": [
        "#@title Download Google Magenta MAESTRO v.2.0.0 Piano MIDI Dataset (~1300 MIDIs)\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip' -P \"/content/shift_invariant_dictionary_learning/maestro/dataset/\"\n",
        "!unzip \"/content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0-midi.zip\" -d \"/content/shift_invariant_dictionary_learning/maestro/dataset/\"\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-19 20:01:56--  https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.132.128, 74.125.202.128, 173.194.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.132.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 59243107 (56M) [application/zip]\n",
            "Saving to: ‘/content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0-midi.zip.1’\n",
            "\n",
            "maestro-v2.0.0-midi 100%[===================>]  56.50M   140MB/s    in 0.4s    \n",
            "\n",
            "2021-07-19 20:01:56 (140 MB/s) - ‘/content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0-midi.zip.1’ saved [59243107/59243107]\n",
            "\n",
            "Archive:  /content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0-midi.zip\n",
            "replace /content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0/maestro-v2.0.0.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-bpkEGxSMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b49f1108-15f6-4b55-c958-6340571f1ab1"
      },
      "source": [
        "#@title Process MAESTRO MIDI DataSet\n",
        "!python3 midi/preprocess_midi.py '/content/shift_invariant_dictionary_learning/maestro/dataset/maestro-v2.0.0'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing midi files and saving to ./dataset/e_piano\n",
            "Found 1282 pieces\n",
            "Preprocessing...\n",
            "50 / 1282\n",
            "100 / 1282\n",
            "150 / 1282\n",
            "200 / 1282\n",
            "250 / 1282\n",
            "300 / 1282\n",
            "350 / 1282\n",
            "400 / 1282\n",
            "450 / 1282\n",
            "500 / 1282\n",
            "550 / 1282\n",
            "600 / 1282\n",
            "650 / 1282\n",
            "700 / 1282\n",
            "750 / 1282\n",
            "800 / 1282\n",
            "850 / 1282\n",
            "900 / 1282\n",
            "950 / 1282\n",
            "1000 / 1282\n",
            "1050 / 1282\n",
            "1100 / 1282\n",
            "1150 / 1282\n",
            "1200 / 1282\n",
            "1250 / 1282\n",
            "Num Train: 967\n",
            "Num Val: 137\n",
            "Num Test: 178\n",
            "Done!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cEwHAIlYrrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "269eb2b9-5636-4efb-d03c-78a03848d53b"
      },
      "source": [
        "from processor import encode_midi, decode_midi\n",
        "\n",
        "                  \n",
        "from dataset.e_piano import create_epiano_datasets, compute_epiano_accuracy\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = create_epiano_datasets(\"/content/MusicTransformer-Pytorch/dataset/e_piano\", 2048)\n",
        "\n",
        "example1 = list(train_dataset)[1].numpy()\n",
        "print(example1)\n",
        "# print(\"torch size \", train_dataset.size())\n",
        "\n",
        "# print(len(list(train_dataset)[9][0]))\n",
        "# tmp = []\n",
        "name = \"test111\"\n",
        "# for point in train_dataset:\n",
        "#     # isthis = decode_midi(point[0].numpy(), name + \".mid\")\n",
        "#     isthis = decode_midi(point[0].numpy())\n",
        "#     tmp.append(isthis.estimate_tempo())\n",
        "\n",
        "\n",
        "# print(\"tempo:\" , tmp )\n",
        "\n",
        "decode_midi(example1[0:2048], name + \".mid\")\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio(name + \".mid\", name + \".wav\")\n",
        "Audio(name + \".wav\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fa7a33a8a071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencode_midi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_midi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me_piano\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_epiano_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_epiano_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'processor'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8kYT_IZNNGX",
        "outputId": "d23674eb-9a0d-4eba-b74e-8db9f79ea224"
      },
      "source": [
        "from midi.processor import encode_midi, decode_midi\n",
        "import torch\n",
        "                  \n",
        "from dataset.e_piano import create_epiano_datasets, compute_epiano_accuracy\n",
        "\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = create_epiano_datasets(\"/content/shift_invariant_dictionary_learning/maestro/dataset/e_piano\", 2048)\n",
        "\n",
        "for i in range(len(train_dataset)):\n",
        "    print(\"train_dataset size\", train_dataset[i].size())\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- WARNING: CUDA devices not detected. This will cause the model to run very slow! -----\n",
            "\n",
            "train_dataset size torch.Size([27598])\n",
            "train_dataset size torch.Size([7127])\n",
            "train_dataset size torch.Size([6280])\n",
            "train_dataset size torch.Size([20405])\n",
            "train_dataset size torch.Size([21539])\n",
            "train_dataset size torch.Size([5695])\n",
            "train_dataset size torch.Size([8794])\n",
            "train_dataset size torch.Size([13449])\n",
            "train_dataset size torch.Size([60001])\n",
            "train_dataset size torch.Size([29564])\n",
            "train_dataset size torch.Size([13995])\n",
            "train_dataset size torch.Size([19848])\n",
            "train_dataset size torch.Size([32770])\n",
            "train_dataset size torch.Size([8401])\n",
            "train_dataset size torch.Size([25104])\n",
            "train_dataset size torch.Size([18446])\n",
            "train_dataset size torch.Size([55231])\n",
            "train_dataset size torch.Size([25043])\n",
            "train_dataset size torch.Size([34346])\n",
            "train_dataset size torch.Size([6636])\n",
            "train_dataset size torch.Size([11528])\n",
            "train_dataset size torch.Size([16572])\n",
            "train_dataset size torch.Size([20498])\n",
            "train_dataset size torch.Size([13383])\n",
            "train_dataset size torch.Size([29278])\n",
            "train_dataset size torch.Size([11198])\n",
            "train_dataset size torch.Size([95254])\n",
            "train_dataset size torch.Size([4832])\n",
            "train_dataset size torch.Size([24510])\n",
            "train_dataset size torch.Size([20767])\n",
            "train_dataset size torch.Size([11047])\n",
            "train_dataset size torch.Size([17188])\n",
            "train_dataset size torch.Size([16365])\n",
            "train_dataset size torch.Size([7637])\n",
            "train_dataset size torch.Size([38802])\n",
            "train_dataset size torch.Size([27095])\n",
            "train_dataset size torch.Size([29596])\n",
            "train_dataset size torch.Size([46019])\n",
            "train_dataset size torch.Size([16037])\n",
            "train_dataset size torch.Size([9090])\n",
            "train_dataset size torch.Size([6359])\n",
            "train_dataset size torch.Size([27854])\n",
            "train_dataset size torch.Size([32749])\n",
            "train_dataset size torch.Size([9162])\n",
            "train_dataset size torch.Size([5574])\n",
            "train_dataset size torch.Size([11455])\n",
            "train_dataset size torch.Size([16946])\n",
            "train_dataset size torch.Size([13451])\n",
            "train_dataset size torch.Size([25958])\n",
            "train_dataset size torch.Size([16037])\n",
            "train_dataset size torch.Size([12522])\n",
            "train_dataset size torch.Size([4405])\n",
            "train_dataset size torch.Size([14729])\n",
            "train_dataset size torch.Size([29063])\n",
            "train_dataset size torch.Size([7571])\n",
            "train_dataset size torch.Size([32886])\n",
            "train_dataset size torch.Size([5908])\n",
            "train_dataset size torch.Size([67531])\n",
            "train_dataset size torch.Size([43160])\n",
            "train_dataset size torch.Size([39044])\n",
            "train_dataset size torch.Size([7519])\n",
            "train_dataset size torch.Size([13605])\n",
            "train_dataset size torch.Size([18644])\n",
            "train_dataset size torch.Size([13428])\n",
            "train_dataset size torch.Size([21941])\n",
            "train_dataset size torch.Size([24714])\n",
            "train_dataset size torch.Size([67265])\n",
            "train_dataset size torch.Size([72710])\n",
            "train_dataset size torch.Size([11402])\n",
            "train_dataset size torch.Size([15699])\n",
            "train_dataset size torch.Size([27518])\n",
            "train_dataset size torch.Size([21089])\n",
            "train_dataset size torch.Size([10266])\n",
            "train_dataset size torch.Size([17489])\n",
            "train_dataset size torch.Size([4059])\n",
            "train_dataset size torch.Size([38881])\n",
            "train_dataset size torch.Size([18197])\n",
            "train_dataset size torch.Size([20238])\n",
            "train_dataset size torch.Size([29504])\n",
            "train_dataset size torch.Size([33377])\n",
            "train_dataset size torch.Size([5789])\n",
            "train_dataset size torch.Size([18520])\n",
            "train_dataset size torch.Size([71927])\n",
            "train_dataset size torch.Size([31801])\n",
            "train_dataset size torch.Size([3741])\n",
            "train_dataset size torch.Size([24900])\n",
            "train_dataset size torch.Size([65664])\n",
            "train_dataset size torch.Size([17504])\n",
            "train_dataset size torch.Size([12019])\n",
            "train_dataset size torch.Size([9538])\n",
            "train_dataset size torch.Size([27522])\n",
            "train_dataset size torch.Size([20511])\n",
            "train_dataset size torch.Size([13939])\n",
            "train_dataset size torch.Size([55562])\n",
            "train_dataset size torch.Size([25579])\n",
            "train_dataset size torch.Size([9935])\n",
            "train_dataset size torch.Size([10124])\n",
            "train_dataset size torch.Size([33940])\n",
            "train_dataset size torch.Size([29187])\n",
            "train_dataset size torch.Size([50765])\n",
            "train_dataset size torch.Size([68925])\n",
            "train_dataset size torch.Size([8941])\n",
            "train_dataset size torch.Size([17130])\n",
            "train_dataset size torch.Size([25892])\n",
            "train_dataset size torch.Size([14408])\n",
            "train_dataset size torch.Size([10432])\n",
            "train_dataset size torch.Size([30053])\n",
            "train_dataset size torch.Size([13048])\n",
            "train_dataset size torch.Size([66758])\n",
            "train_dataset size torch.Size([16670])\n",
            "train_dataset size torch.Size([76141])\n",
            "train_dataset size torch.Size([17440])\n",
            "train_dataset size torch.Size([29827])\n",
            "train_dataset size torch.Size([28819])\n",
            "train_dataset size torch.Size([31370])\n",
            "train_dataset size torch.Size([13655])\n",
            "train_dataset size torch.Size([59000])\n",
            "train_dataset size torch.Size([9517])\n",
            "train_dataset size torch.Size([16511])\n",
            "train_dataset size torch.Size([75158])\n",
            "train_dataset size torch.Size([26367])\n",
            "train_dataset size torch.Size([30081])\n",
            "train_dataset size torch.Size([9352])\n",
            "train_dataset size torch.Size([18992])\n",
            "train_dataset size torch.Size([79300])\n",
            "train_dataset size torch.Size([6675])\n",
            "train_dataset size torch.Size([23716])\n",
            "train_dataset size torch.Size([12417])\n",
            "train_dataset size torch.Size([6494])\n",
            "train_dataset size torch.Size([24035])\n",
            "train_dataset size torch.Size([58772])\n",
            "train_dataset size torch.Size([37990])\n",
            "train_dataset size torch.Size([31299])\n",
            "train_dataset size torch.Size([5652])\n",
            "train_dataset size torch.Size([6561])\n",
            "train_dataset size torch.Size([49817])\n",
            "train_dataset size torch.Size([6608])\n",
            "train_dataset size torch.Size([14277])\n",
            "train_dataset size torch.Size([8452])\n",
            "train_dataset size torch.Size([26535])\n",
            "train_dataset size torch.Size([7027])\n",
            "train_dataset size torch.Size([6673])\n",
            "train_dataset size torch.Size([12987])\n",
            "train_dataset size torch.Size([26146])\n",
            "train_dataset size torch.Size([20936])\n",
            "train_dataset size torch.Size([18018])\n",
            "train_dataset size torch.Size([11500])\n",
            "train_dataset size torch.Size([28672])\n",
            "train_dataset size torch.Size([17249])\n",
            "train_dataset size torch.Size([25327])\n",
            "train_dataset size torch.Size([22894])\n",
            "train_dataset size torch.Size([7268])\n",
            "train_dataset size torch.Size([11556])\n",
            "train_dataset size torch.Size([8273])\n",
            "train_dataset size torch.Size([10120])\n",
            "train_dataset size torch.Size([18130])\n",
            "train_dataset size torch.Size([23996])\n",
            "train_dataset size torch.Size([78811])\n",
            "train_dataset size torch.Size([13364])\n",
            "train_dataset size torch.Size([89897])\n",
            "train_dataset size torch.Size([31757])\n",
            "train_dataset size torch.Size([10058])\n",
            "train_dataset size torch.Size([8786])\n",
            "train_dataset size torch.Size([25667])\n",
            "train_dataset size torch.Size([8038])\n",
            "train_dataset size torch.Size([21667])\n",
            "train_dataset size torch.Size([22183])\n",
            "train_dataset size torch.Size([18318])\n",
            "train_dataset size torch.Size([25697])\n",
            "train_dataset size torch.Size([31871])\n",
            "train_dataset size torch.Size([4650])\n",
            "train_dataset size torch.Size([23999])\n",
            "train_dataset size torch.Size([29747])\n",
            "train_dataset size torch.Size([22900])\n",
            "train_dataset size torch.Size([8744])\n",
            "train_dataset size torch.Size([24502])\n",
            "train_dataset size torch.Size([32614])\n",
            "train_dataset size torch.Size([41089])\n",
            "train_dataset size torch.Size([8634])\n",
            "train_dataset size torch.Size([25959])\n",
            "train_dataset size torch.Size([64590])\n",
            "train_dataset size torch.Size([16671])\n",
            "train_dataset size torch.Size([27268])\n",
            "train_dataset size torch.Size([15498])\n",
            "train_dataset size torch.Size([12434])\n",
            "train_dataset size torch.Size([27092])\n",
            "train_dataset size torch.Size([19045])\n",
            "train_dataset size torch.Size([31941])\n",
            "train_dataset size torch.Size([24670])\n",
            "train_dataset size torch.Size([6041])\n",
            "train_dataset size torch.Size([37060])\n",
            "train_dataset size torch.Size([25596])\n",
            "train_dataset size torch.Size([16061])\n",
            "train_dataset size torch.Size([19494])\n",
            "train_dataset size torch.Size([49525])\n",
            "train_dataset size torch.Size([24263])\n",
            "train_dataset size torch.Size([19733])\n",
            "train_dataset size torch.Size([21748])\n",
            "train_dataset size torch.Size([14650])\n",
            "train_dataset size torch.Size([30646])\n",
            "train_dataset size torch.Size([77832])\n",
            "train_dataset size torch.Size([13794])\n",
            "train_dataset size torch.Size([24120])\n",
            "train_dataset size torch.Size([9628])\n",
            "train_dataset size torch.Size([20844])\n",
            "train_dataset size torch.Size([20215])\n",
            "train_dataset size torch.Size([26071])\n",
            "train_dataset size torch.Size([36509])\n",
            "train_dataset size torch.Size([10750])\n",
            "train_dataset size torch.Size([37444])\n",
            "train_dataset size torch.Size([29987])\n",
            "train_dataset size torch.Size([6647])\n",
            "train_dataset size torch.Size([5])\n",
            "train_dataset size torch.Size([20645])\n",
            "train_dataset size torch.Size([26815])\n",
            "train_dataset size torch.Size([2719])\n",
            "train_dataset size torch.Size([23991])\n",
            "train_dataset size torch.Size([30372])\n",
            "train_dataset size torch.Size([46325])\n",
            "train_dataset size torch.Size([5169])\n",
            "train_dataset size torch.Size([19238])\n",
            "train_dataset size torch.Size([7729])\n",
            "train_dataset size torch.Size([16879])\n",
            "train_dataset size torch.Size([11375])\n",
            "train_dataset size torch.Size([28406])\n",
            "train_dataset size torch.Size([20801])\n",
            "train_dataset size torch.Size([25207])\n",
            "train_dataset size torch.Size([50554])\n",
            "train_dataset size torch.Size([30184])\n",
            "train_dataset size torch.Size([15858])\n",
            "train_dataset size torch.Size([19855])\n",
            "train_dataset size torch.Size([64922])\n",
            "train_dataset size torch.Size([25032])\n",
            "train_dataset size torch.Size([25303])\n",
            "train_dataset size torch.Size([18384])\n",
            "train_dataset size torch.Size([4682])\n",
            "train_dataset size torch.Size([76545])\n",
            "train_dataset size torch.Size([6959])\n",
            "train_dataset size torch.Size([11744])\n",
            "train_dataset size torch.Size([25411])\n",
            "train_dataset size torch.Size([9790])\n",
            "train_dataset size torch.Size([25121])\n",
            "train_dataset size torch.Size([29059])\n",
            "train_dataset size torch.Size([21240])\n",
            "train_dataset size torch.Size([15977])\n",
            "train_dataset size torch.Size([20873])\n",
            "train_dataset size torch.Size([21009])\n",
            "train_dataset size torch.Size([14613])\n",
            "train_dataset size torch.Size([13221])\n",
            "train_dataset size torch.Size([55315])\n",
            "train_dataset size torch.Size([1643])\n",
            "train_dataset size torch.Size([38417])\n",
            "train_dataset size torch.Size([46225])\n",
            "train_dataset size torch.Size([23654])\n",
            "train_dataset size torch.Size([1771])\n",
            "train_dataset size torch.Size([20321])\n",
            "train_dataset size torch.Size([5459])\n",
            "train_dataset size torch.Size([5925])\n",
            "train_dataset size torch.Size([18127])\n",
            "train_dataset size torch.Size([24844])\n",
            "train_dataset size torch.Size([29993])\n",
            "train_dataset size torch.Size([9048])\n",
            "train_dataset size torch.Size([16018])\n",
            "train_dataset size torch.Size([10052])\n",
            "train_dataset size torch.Size([2514])\n",
            "train_dataset size torch.Size([10177])\n",
            "train_dataset size torch.Size([15810])\n",
            "train_dataset size torch.Size([9791])\n",
            "train_dataset size torch.Size([29093])\n",
            "train_dataset size torch.Size([5493])\n",
            "train_dataset size torch.Size([8034])\n",
            "train_dataset size torch.Size([22138])\n",
            "train_dataset size torch.Size([33521])\n",
            "train_dataset size torch.Size([10177])\n",
            "train_dataset size torch.Size([70843])\n",
            "train_dataset size torch.Size([49717])\n",
            "train_dataset size torch.Size([20512])\n",
            "train_dataset size torch.Size([13580])\n",
            "train_dataset size torch.Size([9951])\n",
            "train_dataset size torch.Size([16406])\n",
            "train_dataset size torch.Size([39690])\n",
            "train_dataset size torch.Size([27293])\n",
            "train_dataset size torch.Size([27562])\n",
            "train_dataset size torch.Size([10881])\n",
            "train_dataset size torch.Size([24703])\n",
            "train_dataset size torch.Size([53635])\n",
            "train_dataset size torch.Size([24828])\n",
            "train_dataset size torch.Size([13199])\n",
            "train_dataset size torch.Size([58322])\n",
            "train_dataset size torch.Size([25884])\n",
            "train_dataset size torch.Size([22100])\n",
            "train_dataset size torch.Size([48968])\n",
            "train_dataset size torch.Size([9712])\n",
            "train_dataset size torch.Size([89023])\n",
            "train_dataset size torch.Size([39276])\n",
            "train_dataset size torch.Size([8257])\n",
            "train_dataset size torch.Size([10891])\n",
            "train_dataset size torch.Size([5320])\n",
            "train_dataset size torch.Size([28375])\n",
            "train_dataset size torch.Size([23975])\n",
            "train_dataset size torch.Size([54452])\n",
            "train_dataset size torch.Size([18494])\n",
            "train_dataset size torch.Size([76413])\n",
            "train_dataset size torch.Size([12915])\n",
            "train_dataset size torch.Size([20477])\n",
            "train_dataset size torch.Size([60891])\n",
            "train_dataset size torch.Size([29222])\n",
            "train_dataset size torch.Size([36682])\n",
            "train_dataset size torch.Size([40097])\n",
            "train_dataset size torch.Size([12948])\n",
            "train_dataset size torch.Size([23128])\n",
            "train_dataset size torch.Size([14263])\n",
            "train_dataset size torch.Size([28226])\n",
            "train_dataset size torch.Size([11173])\n",
            "train_dataset size torch.Size([47703])\n",
            "train_dataset size torch.Size([39775])\n",
            "train_dataset size torch.Size([9853])\n",
            "train_dataset size torch.Size([29134])\n",
            "train_dataset size torch.Size([16605])\n",
            "train_dataset size torch.Size([9203])\n",
            "train_dataset size torch.Size([35870])\n",
            "train_dataset size torch.Size([29374])\n",
            "train_dataset size torch.Size([17427])\n",
            "train_dataset size torch.Size([8449])\n",
            "train_dataset size torch.Size([8414])\n",
            "train_dataset size torch.Size([11402])\n",
            "train_dataset size torch.Size([25771])\n",
            "train_dataset size torch.Size([8041])\n",
            "train_dataset size torch.Size([5758])\n",
            "train_dataset size torch.Size([38443])\n",
            "train_dataset size torch.Size([61253])\n",
            "train_dataset size torch.Size([31495])\n",
            "train_dataset size torch.Size([56271])\n",
            "train_dataset size torch.Size([26957])\n",
            "train_dataset size torch.Size([7932])\n",
            "train_dataset size torch.Size([15])\n",
            "train_dataset size torch.Size([49664])\n",
            "train_dataset size torch.Size([25068])\n",
            "train_dataset size torch.Size([11961])\n",
            "train_dataset size torch.Size([24107])\n",
            "train_dataset size torch.Size([24319])\n",
            "train_dataset size torch.Size([100467])\n",
            "train_dataset size torch.Size([30550])\n",
            "train_dataset size torch.Size([13469])\n",
            "train_dataset size torch.Size([24986])\n",
            "train_dataset size torch.Size([79057])\n",
            "train_dataset size torch.Size([15454])\n",
            "train_dataset size torch.Size([68823])\n",
            "train_dataset size torch.Size([36070])\n",
            "train_dataset size torch.Size([29983])\n",
            "train_dataset size torch.Size([16282])\n",
            "train_dataset size torch.Size([8234])\n",
            "train_dataset size torch.Size([25473])\n",
            "train_dataset size torch.Size([31219])\n",
            "train_dataset size torch.Size([11245])\n",
            "train_dataset size torch.Size([17196])\n",
            "train_dataset size torch.Size([10127])\n",
            "train_dataset size torch.Size([20712])\n",
            "train_dataset size torch.Size([16221])\n",
            "train_dataset size torch.Size([29929])\n",
            "train_dataset size torch.Size([58352])\n",
            "train_dataset size torch.Size([10242])\n",
            "train_dataset size torch.Size([24042])\n",
            "train_dataset size torch.Size([7056])\n",
            "train_dataset size torch.Size([69603])\n",
            "train_dataset size torch.Size([24771])\n",
            "train_dataset size torch.Size([74669])\n",
            "train_dataset size torch.Size([29651])\n",
            "train_dataset size torch.Size([5838])\n",
            "train_dataset size torch.Size([20312])\n",
            "train_dataset size torch.Size([6466])\n",
            "train_dataset size torch.Size([26124])\n",
            "train_dataset size torch.Size([19070])\n",
            "train_dataset size torch.Size([22222])\n",
            "train_dataset size torch.Size([23387])\n",
            "train_dataset size torch.Size([9840])\n",
            "train_dataset size torch.Size([2620])\n",
            "train_dataset size torch.Size([33415])\n",
            "train_dataset size torch.Size([13021])\n",
            "train_dataset size torch.Size([27248])\n",
            "train_dataset size torch.Size([20446])\n",
            "train_dataset size torch.Size([20728])\n",
            "train_dataset size torch.Size([49100])\n",
            "train_dataset size torch.Size([25725])\n",
            "train_dataset size torch.Size([7332])\n",
            "train_dataset size torch.Size([26107])\n",
            "train_dataset size torch.Size([39255])\n",
            "train_dataset size torch.Size([30199])\n",
            "train_dataset size torch.Size([10318])\n",
            "train_dataset size torch.Size([9748])\n",
            "train_dataset size torch.Size([14085])\n",
            "train_dataset size torch.Size([7519])\n",
            "train_dataset size torch.Size([27357])\n",
            "train_dataset size torch.Size([13731])\n",
            "train_dataset size torch.Size([43614])\n",
            "train_dataset size torch.Size([16103])\n",
            "train_dataset size torch.Size([9455])\n",
            "train_dataset size torch.Size([39469])\n",
            "train_dataset size torch.Size([9691])\n",
            "train_dataset size torch.Size([32224])\n",
            "train_dataset size torch.Size([30742])\n",
            "train_dataset size torch.Size([13870])\n",
            "train_dataset size torch.Size([64939])\n",
            "train_dataset size torch.Size([23225])\n",
            "train_dataset size torch.Size([24040])\n",
            "train_dataset size torch.Size([15589])\n",
            "train_dataset size torch.Size([21395])\n",
            "train_dataset size torch.Size([24471])\n",
            "train_dataset size torch.Size([5059])\n",
            "train_dataset size torch.Size([25452])\n",
            "train_dataset size torch.Size([31139])\n",
            "train_dataset size torch.Size([31847])\n",
            "train_dataset size torch.Size([22898])\n",
            "train_dataset size torch.Size([13657])\n",
            "train_dataset size torch.Size([21366])\n",
            "train_dataset size torch.Size([15798])\n",
            "train_dataset size torch.Size([4406])\n",
            "train_dataset size torch.Size([6242])\n",
            "train_dataset size torch.Size([18892])\n",
            "train_dataset size torch.Size([37027])\n",
            "train_dataset size torch.Size([58815])\n",
            "train_dataset size torch.Size([6619])\n",
            "train_dataset size torch.Size([13947])\n",
            "train_dataset size torch.Size([26487])\n",
            "train_dataset size torch.Size([11758])\n",
            "train_dataset size torch.Size([8907])\n",
            "train_dataset size torch.Size([6026])\n",
            "train_dataset size torch.Size([8861])\n",
            "train_dataset size torch.Size([29672])\n",
            "train_dataset size torch.Size([20093])\n",
            "train_dataset size torch.Size([6188])\n",
            "train_dataset size torch.Size([29064])\n",
            "train_dataset size torch.Size([34135])\n",
            "train_dataset size torch.Size([8173])\n",
            "train_dataset size torch.Size([18618])\n",
            "train_dataset size torch.Size([51452])\n",
            "train_dataset size torch.Size([36571])\n",
            "train_dataset size torch.Size([16764])\n",
            "train_dataset size torch.Size([23587])\n",
            "train_dataset size torch.Size([20479])\n",
            "train_dataset size torch.Size([58499])\n",
            "train_dataset size torch.Size([24398])\n",
            "train_dataset size torch.Size([9666])\n",
            "train_dataset size torch.Size([16778])\n",
            "train_dataset size torch.Size([67349])\n",
            "train_dataset size torch.Size([11095])\n",
            "train_dataset size torch.Size([6466])\n",
            "train_dataset size torch.Size([8000])\n",
            "train_dataset size torch.Size([8509])\n",
            "train_dataset size torch.Size([9079])\n",
            "train_dataset size torch.Size([18578])\n",
            "train_dataset size torch.Size([67619])\n",
            "train_dataset size torch.Size([75457])\n",
            "train_dataset size torch.Size([5466])\n",
            "train_dataset size torch.Size([10028])\n",
            "train_dataset size torch.Size([17662])\n",
            "train_dataset size torch.Size([49895])\n",
            "train_dataset size torch.Size([8074])\n",
            "train_dataset size torch.Size([28983])\n",
            "train_dataset size torch.Size([69025])\n",
            "train_dataset size torch.Size([28377])\n",
            "train_dataset size torch.Size([13975])\n",
            "train_dataset size torch.Size([8734])\n",
            "train_dataset size torch.Size([20903])\n",
            "train_dataset size torch.Size([50300])\n",
            "train_dataset size torch.Size([12303])\n",
            "train_dataset size torch.Size([35748])\n",
            "train_dataset size torch.Size([9033])\n",
            "train_dataset size torch.Size([79047])\n",
            "train_dataset size torch.Size([21977])\n",
            "train_dataset size torch.Size([31523])\n",
            "train_dataset size torch.Size([11200])\n",
            "train_dataset size torch.Size([16149])\n",
            "train_dataset size torch.Size([11387])\n",
            "train_dataset size torch.Size([13808])\n",
            "train_dataset size torch.Size([14247])\n",
            "train_dataset size torch.Size([29924])\n",
            "train_dataset size torch.Size([4972])\n",
            "train_dataset size torch.Size([11294])\n",
            "train_dataset size torch.Size([5932])\n",
            "train_dataset size torch.Size([72279])\n",
            "train_dataset size torch.Size([12046])\n",
            "train_dataset size torch.Size([22295])\n",
            "train_dataset size torch.Size([11355])\n",
            "train_dataset size torch.Size([10850])\n",
            "train_dataset size torch.Size([19907])\n",
            "train_dataset size torch.Size([37890])\n",
            "train_dataset size torch.Size([11873])\n",
            "train_dataset size torch.Size([5760])\n",
            "train_dataset size torch.Size([14044])\n",
            "train_dataset size torch.Size([17794])\n",
            "train_dataset size torch.Size([72693])\n",
            "train_dataset size torch.Size([6805])\n",
            "train_dataset size torch.Size([9587])\n",
            "train_dataset size torch.Size([45719])\n",
            "train_dataset size torch.Size([33772])\n",
            "train_dataset size torch.Size([11658])\n",
            "train_dataset size torch.Size([30051])\n",
            "train_dataset size torch.Size([42349])\n",
            "train_dataset size torch.Size([5738])\n",
            "train_dataset size torch.Size([18282])\n",
            "train_dataset size torch.Size([24079])\n",
            "train_dataset size torch.Size([27935])\n",
            "train_dataset size torch.Size([12381])\n",
            "train_dataset size torch.Size([19234])\n",
            "train_dataset size torch.Size([10594])\n",
            "train_dataset size torch.Size([19841])\n",
            "train_dataset size torch.Size([6195])\n",
            "train_dataset size torch.Size([12366])\n",
            "train_dataset size torch.Size([10674])\n",
            "train_dataset size torch.Size([20965])\n",
            "train_dataset size torch.Size([39641])\n",
            "train_dataset size torch.Size([48969])\n",
            "train_dataset size torch.Size([5288])\n",
            "train_dataset size torch.Size([8542])\n",
            "train_dataset size torch.Size([4956])\n",
            "train_dataset size torch.Size([8381])\n",
            "train_dataset size torch.Size([27576])\n",
            "train_dataset size torch.Size([9324])\n",
            "train_dataset size torch.Size([31969])\n",
            "train_dataset size torch.Size([33170])\n",
            "train_dataset size torch.Size([20011])\n",
            "train_dataset size torch.Size([8293])\n",
            "train_dataset size torch.Size([9551])\n",
            "train_dataset size torch.Size([9009])\n",
            "train_dataset size torch.Size([26663])\n",
            "train_dataset size torch.Size([56944])\n",
            "train_dataset size torch.Size([16214])\n",
            "train_dataset size torch.Size([49010])\n",
            "train_dataset size torch.Size([29278])\n",
            "train_dataset size torch.Size([34055])\n",
            "train_dataset size torch.Size([25520])\n",
            "train_dataset size torch.Size([58708])\n",
            "train_dataset size torch.Size([4608])\n",
            "train_dataset size torch.Size([22626])\n",
            "train_dataset size torch.Size([9066])\n",
            "train_dataset size torch.Size([5901])\n",
            "train_dataset size torch.Size([19354])\n",
            "train_dataset size torch.Size([31071])\n",
            "train_dataset size torch.Size([29580])\n",
            "train_dataset size torch.Size([31826])\n",
            "train_dataset size torch.Size([11121])\n",
            "train_dataset size torch.Size([35608])\n",
            "train_dataset size torch.Size([3813])\n",
            "train_dataset size torch.Size([24615])\n",
            "train_dataset size torch.Size([29308])\n",
            "train_dataset size torch.Size([29392])\n",
            "train_dataset size torch.Size([3417])\n",
            "train_dataset size torch.Size([38993])\n",
            "train_dataset size torch.Size([32538])\n",
            "train_dataset size torch.Size([38923])\n",
            "train_dataset size torch.Size([23343])\n",
            "train_dataset size torch.Size([34208])\n",
            "train_dataset size torch.Size([25554])\n",
            "train_dataset size torch.Size([76328])\n",
            "train_dataset size torch.Size([8260])\n",
            "train_dataset size torch.Size([7911])\n",
            "train_dataset size torch.Size([9024])\n",
            "train_dataset size torch.Size([3777])\n",
            "train_dataset size torch.Size([9516])\n",
            "train_dataset size torch.Size([65412])\n",
            "train_dataset size torch.Size([13167])\n",
            "train_dataset size torch.Size([47600])\n",
            "train_dataset size torch.Size([8924])\n",
            "train_dataset size torch.Size([31820])\n",
            "train_dataset size torch.Size([24770])\n",
            "train_dataset size torch.Size([29477])\n",
            "train_dataset size torch.Size([32998])\n",
            "train_dataset size torch.Size([16843])\n",
            "train_dataset size torch.Size([12971])\n",
            "train_dataset size torch.Size([11246])\n",
            "train_dataset size torch.Size([29599])\n",
            "train_dataset size torch.Size([11050])\n",
            "train_dataset size torch.Size([13533])\n",
            "train_dataset size torch.Size([33011])\n",
            "train_dataset size torch.Size([14647])\n",
            "train_dataset size torch.Size([18757])\n",
            "train_dataset size torch.Size([30891])\n",
            "train_dataset size torch.Size([17951])\n",
            "train_dataset size torch.Size([24169])\n",
            "train_dataset size torch.Size([11956])\n",
            "train_dataset size torch.Size([25798])\n",
            "train_dataset size torch.Size([8593])\n",
            "train_dataset size torch.Size([64908])\n",
            "train_dataset size torch.Size([19992])\n",
            "train_dataset size torch.Size([34288])\n",
            "train_dataset size torch.Size([5894])\n",
            "train_dataset size torch.Size([5946])\n",
            "train_dataset size torch.Size([8001])\n",
            "train_dataset size torch.Size([47293])\n",
            "train_dataset size torch.Size([4732])\n",
            "train_dataset size torch.Size([21303])\n",
            "train_dataset size torch.Size([20589])\n",
            "train_dataset size torch.Size([6524])\n",
            "train_dataset size torch.Size([12589])\n",
            "train_dataset size torch.Size([29804])\n",
            "train_dataset size torch.Size([9567])\n",
            "train_dataset size torch.Size([29887])\n",
            "train_dataset size torch.Size([11468])\n",
            "train_dataset size torch.Size([8718])\n",
            "train_dataset size torch.Size([11575])\n",
            "train_dataset size torch.Size([34337])\n",
            "train_dataset size torch.Size([30582])\n",
            "train_dataset size torch.Size([9747])\n",
            "train_dataset size torch.Size([30957])\n",
            "train_dataset size torch.Size([17550])\n",
            "train_dataset size torch.Size([22029])\n",
            "train_dataset size torch.Size([67943])\n",
            "train_dataset size torch.Size([25808])\n",
            "train_dataset size torch.Size([9509])\n",
            "train_dataset size torch.Size([9191])\n",
            "train_dataset size torch.Size([11296])\n",
            "train_dataset size torch.Size([27144])\n",
            "train_dataset size torch.Size([39613])\n",
            "train_dataset size torch.Size([74353])\n",
            "train_dataset size torch.Size([13446])\n",
            "train_dataset size torch.Size([26861])\n",
            "train_dataset size torch.Size([38528])\n",
            "train_dataset size torch.Size([12435])\n",
            "train_dataset size torch.Size([33692])\n",
            "train_dataset size torch.Size([26456])\n",
            "train_dataset size torch.Size([67020])\n",
            "train_dataset size torch.Size([32802])\n",
            "train_dataset size torch.Size([78384])\n",
            "train_dataset size torch.Size([12574])\n",
            "train_dataset size torch.Size([24784])\n",
            "train_dataset size torch.Size([9391])\n",
            "train_dataset size torch.Size([25823])\n",
            "train_dataset size torch.Size([7184])\n",
            "train_dataset size torch.Size([24126])\n",
            "train_dataset size torch.Size([6714])\n",
            "train_dataset size torch.Size([9528])\n",
            "train_dataset size torch.Size([66709])\n",
            "train_dataset size torch.Size([21496])\n",
            "train_dataset size torch.Size([11430])\n",
            "train_dataset size torch.Size([57639])\n",
            "train_dataset size torch.Size([28539])\n",
            "train_dataset size torch.Size([7719])\n",
            "train_dataset size torch.Size([39092])\n",
            "train_dataset size torch.Size([4138])\n",
            "train_dataset size torch.Size([29547])\n",
            "train_dataset size torch.Size([5754])\n",
            "train_dataset size torch.Size([26892])\n",
            "train_dataset size torch.Size([21605])\n",
            "train_dataset size torch.Size([17677])\n",
            "train_dataset size torch.Size([80930])\n",
            "train_dataset size torch.Size([13658])\n",
            "train_dataset size torch.Size([23632])\n",
            "train_dataset size torch.Size([30471])\n",
            "train_dataset size torch.Size([33138])\n",
            "train_dataset size torch.Size([9475])\n",
            "train_dataset size torch.Size([11382])\n",
            "train_dataset size torch.Size([10607])\n",
            "train_dataset size torch.Size([30839])\n",
            "train_dataset size torch.Size([16351])\n",
            "train_dataset size torch.Size([6581])\n",
            "train_dataset size torch.Size([18975])\n",
            "train_dataset size torch.Size([9524])\n",
            "train_dataset size torch.Size([13954])\n",
            "train_dataset size torch.Size([31264])\n",
            "train_dataset size torch.Size([22434])\n",
            "train_dataset size torch.Size([25508])\n",
            "train_dataset size torch.Size([12615])\n",
            "train_dataset size torch.Size([6813])\n",
            "train_dataset size torch.Size([10381])\n",
            "train_dataset size torch.Size([5922])\n",
            "train_dataset size torch.Size([36625])\n",
            "train_dataset size torch.Size([24335])\n",
            "train_dataset size torch.Size([65093])\n",
            "train_dataset size torch.Size([9554])\n",
            "train_dataset size torch.Size([9647])\n",
            "train_dataset size torch.Size([16153])\n",
            "train_dataset size torch.Size([29112])\n",
            "train_dataset size torch.Size([31912])\n",
            "train_dataset size torch.Size([25046])\n",
            "train_dataset size torch.Size([21016])\n",
            "train_dataset size torch.Size([25180])\n",
            "train_dataset size torch.Size([5942])\n",
            "train_dataset size torch.Size([10505])\n",
            "train_dataset size torch.Size([45620])\n",
            "train_dataset size torch.Size([25170])\n",
            "train_dataset size torch.Size([20779])\n",
            "train_dataset size torch.Size([9112])\n",
            "train_dataset size torch.Size([9447])\n",
            "train_dataset size torch.Size([20388])\n",
            "train_dataset size torch.Size([72439])\n",
            "train_dataset size torch.Size([586])\n",
            "train_dataset size torch.Size([7934])\n",
            "train_dataset size torch.Size([40344])\n",
            "train_dataset size torch.Size([24822])\n",
            "train_dataset size torch.Size([14247])\n",
            "train_dataset size torch.Size([73008])\n",
            "train_dataset size torch.Size([30065])\n",
            "train_dataset size torch.Size([30002])\n",
            "train_dataset size torch.Size([17709])\n",
            "train_dataset size torch.Size([22846])\n",
            "train_dataset size torch.Size([29683])\n",
            "train_dataset size torch.Size([18586])\n",
            "train_dataset size torch.Size([46987])\n",
            "train_dataset size torch.Size([39981])\n",
            "train_dataset size torch.Size([47418])\n",
            "train_dataset size torch.Size([20148])\n",
            "train_dataset size torch.Size([25156])\n",
            "train_dataset size torch.Size([11741])\n",
            "train_dataset size torch.Size([29530])\n",
            "train_dataset size torch.Size([25842])\n",
            "train_dataset size torch.Size([63812])\n",
            "train_dataset size torch.Size([6585])\n",
            "train_dataset size torch.Size([9047])\n",
            "train_dataset size torch.Size([6948])\n",
            "train_dataset size torch.Size([13993])\n",
            "train_dataset size torch.Size([28194])\n",
            "train_dataset size torch.Size([27396])\n",
            "train_dataset size torch.Size([64828])\n",
            "train_dataset size torch.Size([15394])\n",
            "train_dataset size torch.Size([51613])\n",
            "train_dataset size torch.Size([8018])\n",
            "train_dataset size torch.Size([16594])\n",
            "train_dataset size torch.Size([13183])\n",
            "train_dataset size torch.Size([13296])\n",
            "train_dataset size torch.Size([11580])\n",
            "train_dataset size torch.Size([22066])\n",
            "train_dataset size torch.Size([38924])\n",
            "train_dataset size torch.Size([31402])\n",
            "train_dataset size torch.Size([14067])\n",
            "train_dataset size torch.Size([24842])\n",
            "train_dataset size torch.Size([55703])\n",
            "train_dataset size torch.Size([49956])\n",
            "train_dataset size torch.Size([16908])\n",
            "train_dataset size torch.Size([11225])\n",
            "train_dataset size torch.Size([8459])\n",
            "train_dataset size torch.Size([7913])\n",
            "train_dataset size torch.Size([36777])\n",
            "train_dataset size torch.Size([11023])\n",
            "train_dataset size torch.Size([55734])\n",
            "train_dataset size torch.Size([20818])\n",
            "train_dataset size torch.Size([6275])\n",
            "train_dataset size torch.Size([25789])\n",
            "train_dataset size torch.Size([26112])\n",
            "train_dataset size torch.Size([25878])\n",
            "train_dataset size torch.Size([5745])\n",
            "train_dataset size torch.Size([14220])\n",
            "train_dataset size torch.Size([21348])\n",
            "train_dataset size torch.Size([46295])\n",
            "train_dataset size torch.Size([10945])\n",
            "train_dataset size torch.Size([24713])\n",
            "train_dataset size torch.Size([9238])\n",
            "train_dataset size torch.Size([24993])\n",
            "train_dataset size torch.Size([50350])\n",
            "train_dataset size torch.Size([14805])\n",
            "train_dataset size torch.Size([62410])\n",
            "train_dataset size torch.Size([30645])\n",
            "train_dataset size torch.Size([4788])\n",
            "train_dataset size torch.Size([7170])\n",
            "train_dataset size torch.Size([6458])\n",
            "train_dataset size torch.Size([39248])\n",
            "train_dataset size torch.Size([9713])\n",
            "train_dataset size torch.Size([9144])\n",
            "train_dataset size torch.Size([36747])\n",
            "train_dataset size torch.Size([21075])\n",
            "train_dataset size torch.Size([15386])\n",
            "train_dataset size torch.Size([35751])\n",
            "train_dataset size torch.Size([30518])\n",
            "train_dataset size torch.Size([9456])\n",
            "train_dataset size torch.Size([25899])\n",
            "train_dataset size torch.Size([9140])\n",
            "train_dataset size torch.Size([12171])\n",
            "train_dataset size torch.Size([79847])\n",
            "train_dataset size torch.Size([19916])\n",
            "train_dataset size torch.Size([11304])\n",
            "train_dataset size torch.Size([25629])\n",
            "train_dataset size torch.Size([29574])\n",
            "train_dataset size torch.Size([14738])\n",
            "train_dataset size torch.Size([29833])\n",
            "train_dataset size torch.Size([73353])\n",
            "train_dataset size torch.Size([31958])\n",
            "train_dataset size torch.Size([9518])\n",
            "train_dataset size torch.Size([12583])\n",
            "train_dataset size torch.Size([9891])\n",
            "train_dataset size torch.Size([37004])\n",
            "train_dataset size torch.Size([19392])\n",
            "train_dataset size torch.Size([37767])\n",
            "train_dataset size torch.Size([22450])\n",
            "train_dataset size torch.Size([25488])\n",
            "train_dataset size torch.Size([10946])\n",
            "train_dataset size torch.Size([4017])\n",
            "train_dataset size torch.Size([89115])\n",
            "train_dataset size torch.Size([8869])\n",
            "train_dataset size torch.Size([25149])\n",
            "train_dataset size torch.Size([46979])\n",
            "train_dataset size torch.Size([32106])\n",
            "train_dataset size torch.Size([24801])\n",
            "train_dataset size torch.Size([6061])\n",
            "train_dataset size torch.Size([5651])\n",
            "train_dataset size torch.Size([48138])\n",
            "train_dataset size torch.Size([9074])\n",
            "train_dataset size torch.Size([30631])\n",
            "train_dataset size torch.Size([9508])\n",
            "train_dataset size torch.Size([6900])\n",
            "train_dataset size torch.Size([16475])\n",
            "train_dataset size torch.Size([39572])\n",
            "train_dataset size torch.Size([9674])\n",
            "train_dataset size torch.Size([55454])\n",
            "train_dataset size torch.Size([33269])\n",
            "train_dataset size torch.Size([29882])\n",
            "train_dataset size torch.Size([13298])\n",
            "train_dataset size torch.Size([16031])\n",
            "train_dataset size torch.Size([32825])\n",
            "train_dataset size torch.Size([58077])\n",
            "train_dataset size torch.Size([11577])\n",
            "train_dataset size torch.Size([67616])\n",
            "train_dataset size torch.Size([25195])\n",
            "train_dataset size torch.Size([7304])\n",
            "train_dataset size torch.Size([25058])\n",
            "train_dataset size torch.Size([9073])\n",
            "train_dataset size torch.Size([19626])\n",
            "train_dataset size torch.Size([12839])\n",
            "train_dataset size torch.Size([13795])\n",
            "train_dataset size torch.Size([61833])\n",
            "train_dataset size torch.Size([6633])\n",
            "train_dataset size torch.Size([29506])\n",
            "train_dataset size torch.Size([7874])\n",
            "train_dataset size torch.Size([11572])\n",
            "train_dataset size torch.Size([25519])\n",
            "train_dataset size torch.Size([19277])\n",
            "train_dataset size torch.Size([29649])\n",
            "train_dataset size torch.Size([14983])\n",
            "train_dataset size torch.Size([61667])\n",
            "train_dataset size torch.Size([30335])\n",
            "train_dataset size torch.Size([23747])\n",
            "train_dataset size torch.Size([53685])\n",
            "train_dataset size torch.Size([66370])\n",
            "train_dataset size torch.Size([11203])\n",
            "train_dataset size torch.Size([29329])\n",
            "train_dataset size torch.Size([40244])\n",
            "train_dataset size torch.Size([24909])\n",
            "train_dataset size torch.Size([12772])\n",
            "train_dataset size torch.Size([5847])\n",
            "train_dataset size torch.Size([21819])\n",
            "train_dataset size torch.Size([4203])\n",
            "train_dataset size torch.Size([11942])\n",
            "train_dataset size torch.Size([11044])\n",
            "train_dataset size torch.Size([4412])\n",
            "train_dataset size torch.Size([5813])\n",
            "train_dataset size torch.Size([19391])\n",
            "train_dataset size torch.Size([79155])\n",
            "train_dataset size torch.Size([5858])\n",
            "train_dataset size torch.Size([83541])\n",
            "train_dataset size torch.Size([21103])\n",
            "train_dataset size torch.Size([86959])\n",
            "train_dataset size torch.Size([17863])\n",
            "train_dataset size torch.Size([30104])\n",
            "train_dataset size torch.Size([27526])\n",
            "train_dataset size torch.Size([20753])\n",
            "train_dataset size torch.Size([13295])\n",
            "train_dataset size torch.Size([10715])\n",
            "train_dataset size torch.Size([56431])\n",
            "train_dataset size torch.Size([23062])\n",
            "train_dataset size torch.Size([12018])\n",
            "train_dataset size torch.Size([6929])\n",
            "train_dataset size torch.Size([36401])\n",
            "train_dataset size torch.Size([30349])\n",
            "train_dataset size torch.Size([11743])\n",
            "train_dataset size torch.Size([6659])\n",
            "train_dataset size torch.Size([8867])\n",
            "train_dataset size torch.Size([5869])\n",
            "train_dataset size torch.Size([16993])\n",
            "train_dataset size torch.Size([49718])\n",
            "train_dataset size torch.Size([5981])\n",
            "train_dataset size torch.Size([9292])\n",
            "train_dataset size torch.Size([61933])\n",
            "train_dataset size torch.Size([7644])\n",
            "train_dataset size torch.Size([10346])\n",
            "train_dataset size torch.Size([80613])\n",
            "train_dataset size torch.Size([32983])\n",
            "train_dataset size torch.Size([54306])\n",
            "train_dataset size torch.Size([27207])\n",
            "train_dataset size torch.Size([16123])\n",
            "train_dataset size torch.Size([7838])\n",
            "train_dataset size torch.Size([23066])\n",
            "train_dataset size torch.Size([9642])\n",
            "train_dataset size torch.Size([7088])\n",
            "train_dataset size torch.Size([31539])\n",
            "train_dataset size torch.Size([26297])\n",
            "train_dataset size torch.Size([6667])\n",
            "train_dataset size torch.Size([10377])\n",
            "train_dataset size torch.Size([48131])\n",
            "train_dataset size torch.Size([8099])\n",
            "train_dataset size torch.Size([14419])\n",
            "train_dataset size torch.Size([17986])\n",
            "train_dataset size torch.Size([47809])\n",
            "train_dataset size torch.Size([8990])\n",
            "train_dataset size torch.Size([9814])\n",
            "train_dataset size torch.Size([30414])\n",
            "train_dataset size torch.Size([13570])\n",
            "train_dataset size torch.Size([47057])\n",
            "train_dataset size torch.Size([25360])\n",
            "train_dataset size torch.Size([14298])\n",
            "train_dataset size torch.Size([19834])\n",
            "train_dataset size torch.Size([17217])\n",
            "train_dataset size torch.Size([12338])\n",
            "train_dataset size torch.Size([9652])\n",
            "train_dataset size torch.Size([9335])\n",
            "train_dataset size torch.Size([18915])\n",
            "train_dataset size torch.Size([12721])\n",
            "train_dataset size torch.Size([26699])\n",
            "train_dataset size torch.Size([39384])\n",
            "train_dataset size torch.Size([11940])\n",
            "train_dataset size torch.Size([19209])\n",
            "train_dataset size torch.Size([75546])\n",
            "train_dataset size torch.Size([30552])\n",
            "train_dataset size torch.Size([39559])\n",
            "train_dataset size torch.Size([4984])\n",
            "train_dataset size torch.Size([6181])\n",
            "train_dataset size torch.Size([12740])\n",
            "train_dataset size torch.Size([11608])\n",
            "train_dataset size torch.Size([16696])\n",
            "train_dataset size torch.Size([21878])\n",
            "train_dataset size torch.Size([30663])\n",
            "train_dataset size torch.Size([30498])\n",
            "train_dataset size torch.Size([17849])\n",
            "train_dataset size torch.Size([11068])\n",
            "train_dataset size torch.Size([26561])\n",
            "train_dataset size torch.Size([4393])\n",
            "train_dataset size torch.Size([26994])\n",
            "train_dataset size torch.Size([28047])\n",
            "train_dataset size torch.Size([8529])\n",
            "train_dataset size torch.Size([30188])\n",
            "train_dataset size torch.Size([10070])\n",
            "train_dataset size torch.Size([11099])\n",
            "train_dataset size torch.Size([68972])\n",
            "train_dataset size torch.Size([8983])\n",
            "train_dataset size torch.Size([24473])\n",
            "train_dataset size torch.Size([40309])\n",
            "train_dataset size torch.Size([10229])\n",
            "train_dataset size torch.Size([26848])\n",
            "train_dataset size torch.Size([24482])\n",
            "train_dataset size torch.Size([20324])\n",
            "train_dataset size torch.Size([25288])\n",
            "train_dataset size torch.Size([47823])\n",
            "train_dataset size torch.Size([11731])\n",
            "train_dataset size torch.Size([17155])\n",
            "train_dataset size torch.Size([6652])\n",
            "train_dataset size torch.Size([85007])\n",
            "train_dataset size torch.Size([78719])\n",
            "train_dataset size torch.Size([18045])\n",
            "train_dataset size torch.Size([11525])\n",
            "train_dataset size torch.Size([10020])\n",
            "train_dataset size torch.Size([29807])\n",
            "train_dataset size torch.Size([12142])\n",
            "train_dataset size torch.Size([24449])\n",
            "train_dataset size torch.Size([24891])\n",
            "train_dataset size torch.Size([13433])\n",
            "train_dataset size torch.Size([10662])\n",
            "train_dataset size torch.Size([30471])\n",
            "train_dataset size torch.Size([12252])\n",
            "train_dataset size torch.Size([7164])\n",
            "train_dataset size torch.Size([20313])\n",
            "train_dataset size torch.Size([13500])\n",
            "train_dataset size torch.Size([10197])\n",
            "train_dataset size torch.Size([29905])\n",
            "train_dataset size torch.Size([15929])\n",
            "train_dataset size torch.Size([12871])\n",
            "train_dataset size torch.Size([11073])\n",
            "train_dataset size torch.Size([46720])\n",
            "train_dataset size torch.Size([6478])\n",
            "train_dataset size torch.Size([24090])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwCQIziNwHxe"
      },
      "source": [
        "# Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17-TGkI_PWUy"
      },
      "source": [
        "#@title Pytorch for DL\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch.nn.utils import weight_norm\n",
        "import numpy as np\n",
        "\n",
        "def get_model_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    return params"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "XApH6urQOPLj"
      },
      "source": [
        "#@title KWTA\n",
        "\n",
        "\n",
        "class SparsifyBase(nn.Module):\n",
        "    def __init__(self, sparse_ratio=0.5):\n",
        "        super(SparsifyBase, self).__init__()\n",
        "        self.sr = sparse_ratio\n",
        "        self.preact = None\n",
        "        self.act = None\n",
        "    def get_activation(self):\n",
        "        def hook(model, input, output):\n",
        "            self.preact = input[0].cpu().detach().clone()\n",
        "            self.act = output.cpu().detach().clone()\n",
        "        return hook\n",
        "    def record_activation(self):\n",
        "        self.register_forward_hook(self.get_activation())\n",
        "\n",
        "\n",
        "class Sparsify1D_kactive(SparsifyBase):\n",
        "    def __init__(self, k=1):\n",
        "        super(Sparsify1D_kactive, self).__init__()\n",
        "        self.k = k\n",
        "    def forward(self, x):\n",
        "        m = torch.zeros(x.shape).to(device)\n",
        "        for i in range(self.k):\n",
        "            indeces = x.topk(self.k, dim=1)[1][:, i]\n",
        "            m += torch.mul(torch.zeros(x.shape).to(device).scatter(1, indeces.unsqueeze(1), 1), x)\n",
        "            # print(\"\\n hi\", m )\n",
        "        return m.double()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "OQlt19U2OSAs"
      },
      "source": [
        "#@title TCN \n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 1)\n",
        "        self.conv2.weight.data.normal_(0, 1)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"block \", x.size())\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        # print(\"last layer conv\", self.network[-1].conv2.weight.data[:,0,:].size())\n",
        "        # print(\"last layer conv\", self.network[-1].conv2.weight.data[:,0,:])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "0_AWraunOaVh"
      },
      "source": [
        "#@title TCN - Autoeconder \n",
        "\n",
        "class TCNAutoencoder(nn.Module):\n",
        "    def __init__(self, kernel_size, dropout, wta_k):\n",
        "        super(TCNAutoencoder, self).__init__()\n",
        "        self.wta = Sparsify1D_kactive(k = wta_k)\n",
        "        self.feature = TemporalConvNet(1, [8,16,24,48], kernel_size, dropout=dropout).double()\n",
        "        self.encoder = torch.nn.Conv1d(in_channels=48, out_channels=1000, kernel_size=kernel_size, padding=0, bias=True, stride=4)\n",
        "        self.decoder = torch.nn.ConvTranspose1d(in_channels=1000, out_channels=1, kernel_size=kernel_size, padding=0, bias=True, stride=4)\n",
        "        # self.encoder.weight.data.normal_(30)\n",
        "        # self.decoder.weight.data.normal_(300)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.code = None\n",
        "        # torch.nn.init.xavier_uniform(self.encoder.weight)\n",
        "        # torch.nn.init.xavier_uniform(self.decoder.weight)\n",
        "    def get_kernels(self):\n",
        "        return self.decoder.weight.data[:,0,:]\n",
        "    def feature_map(self, x):\n",
        "        code = self.code\n",
        "        return code\n",
        "    def forward(self, x):\n",
        "        # x needs to have dimension (N, C, L) in order to be passed into CNN\n",
        "        output = self.feature(x)\n",
        "        self.code = self.wta(self.encoder(output))\n",
        "        output = self.decoder(self.code )\n",
        "        return output\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQs5u8O3OdLq"
      },
      "source": [
        "# Model training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5TUm_ewOcma",
        "outputId": "150d5377-fe8c-41d9-ef50-b5e81d8b4962"
      },
      "source": [
        "#@title GO\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(\"Using device: \", device)\n",
        "\n",
        "model = TCNAutoencoder(kernel_size=4, \n",
        "                       dropout=0.1, \n",
        "                       wta_k = 100).to(device).double()\n",
        "print(\"TCNAutoencoder trainable parameters: \", get_model_parameters(model))\n",
        "\n",
        "# model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.MSELoss().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=.01, weight_decay = 0.00001, momentum=0.05) ##this has weight decay just like you implemented\n",
        "optimizer = optim.AdamW(model.parameters(), lr=.005,  betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=True) ##this has weight decay just like you implemented\n",
        "epochs = 60\n",
        "history = {\"loss\": []}\n",
        "print(\"test \" ,max(1, model.wta.k - 1) )\n",
        "calc = []\n",
        "for i in range(epochs):\n",
        "    #decaying WTA\n",
        "    if i % 10 == 0 and i != 0:\n",
        "        model.wta.k = max(1, model.wta.k - 5)\n",
        "        print(\"model.wta.k: \", model.wta.k)\n",
        "    for train_data in train_dataset:\n",
        "      # calc.extend(train_data.flatten().numpy())\n",
        "      #normalize \n",
        "      train_data = (train_data - 224.15541543187527) / 111.14747885919755\n",
        "      #preprocess\n",
        "      lenby4 = len(train_data) // 4\n",
        "      train_data = train_data[None, None, 0:lenby4*4].to(device).double()\n",
        "      \n",
        "      #preprocess\n",
        "      optimizer.zero_grad()\n",
        "      output = model(train_data)\n",
        "\n",
        "      loss = loss_fn(output, train_data)\n",
        "      loss.backward()\n",
        "      # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "      optimizer.step()\n",
        "      history[\"loss\"].append(float(loss))\n",
        "      if i % 1 == 0:\n",
        "          print(\"Epoch : {} \\t Loss : {} \\t Code_Sparsity: {} \".format(i, round(float(loss),7), torch.count_nonzero(model.code)))\n",
        "          \n",
        "\n",
        "# print(len(calc))\n",
        "# print(np.mean(calc, axis=0))\n",
        "# print(np.std(calc, axis=0))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23525566\n",
            "224.15541543187527\n",
            "111.14747885919755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLmF97wmTCa2",
        "cellView": "code"
      },
      "source": [
        "#@title Test Recustruction \n",
        "\n",
        "def get_code(model,input):\n",
        "    model(input)\n",
        "    return model.code\n",
        "\n",
        "\n",
        "def play_example(input):\n",
        "    decode_midi(input[0:2048], name + \".mid\")\n",
        "    FluidSynth(\"/content/font.sf2\").midi_to_audio(name + \".mid\", name + \".wav\")\n",
        "    Audio(name + \".wav\")\n",
        "\n",
        "\n",
        "#make it a keep top n \n",
        "def exchange_max_rows(A,B):\n",
        "    maxrowA = torch.argmax(A.sum(1))\n",
        "    maxrowB = torch.argmax(B.sum(1))\n",
        "    rowA = A[maxrowA:maxrowA+1,].clone()\n",
        "    rowB = B[maxrowB:maxrowB+1,].clone()\n",
        "    # print(\"rowA \",rowA )\n",
        "    # print(\"rowB \",rowB )\n",
        "    A[maxrowB:maxrowB+1,] =  rowB\n",
        "    B[maxrowA:maxrowA+1,] =  rowA\n",
        "    return A,B\n",
        "\n",
        "#make it a keep top n \n",
        "def keep_topk(A,k):\n",
        "    mask = torch.zeros(A.shape).to(device)\n",
        "    v, i  = torch.topk(A.sum(1), k)\n",
        "    print(\"\\n index is\", i)\n",
        "    mask[i, ] = True\n",
        "    return mask * A\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dNVJbqsTEpu"
      },
      "source": [
        "    \n",
        "index_example = 207\n",
        "\n",
        "\n",
        "#get raw_input\n",
        "raw_input = train_dataset[index_example]\n",
        "\n",
        "print(raw_input.shape)\n",
        "print(raw_input.max())\n",
        "\n",
        "\n",
        "print(\"orginal 1\")\n",
        "name = \"music\"\n",
        "decode_midi(raw_input.numpy()[0:300], name + \".mid\")\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio(name + \".mid\", name + \".wav\")\n",
        "Audio(name + \".wav\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzS9350AoMAN"
      },
      "source": [
        "print(\"reconstructed\")\n",
        "name = \"music_rec\"\n",
        "\n",
        "raw_input = (raw_input - 224.5851314855734) / 111.61066023994307\n",
        "\n",
        "train_data = raw_input[None, None, 0:(len(raw_input) // 4)*4].to(device).double()\n",
        "print(\"train_data size\", train_data.shape)\n",
        "\n",
        "model_out = model(train_data)[0,0,:]\n",
        "model_out = (model_out * 111.61066023994307) + 224.5851314855734\n",
        "\n",
        "print(\"model_out size\", model_out.shape)\n",
        "print(\"model_out max\", model_out.max())\n",
        "\n",
        "print(model_out.cpu().detach().numpy().astype(int))\n",
        "decode_midi(model_out.cpu().detach().numpy().astype(int)[0:300], name + \".mid\")\n",
        "FluidSynth(\"/content/font.sf2\").midi_to_audio(name + \".mid\", name + \".wav\")\n",
        "Audio(name + \".wav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1H0-04imJZH"
      },
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shVyUhS2iXwT"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.pth') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}