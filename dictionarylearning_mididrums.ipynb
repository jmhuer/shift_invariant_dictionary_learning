{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dictionarylearning_mididrums.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOb9UL9RnldHTXtvjqm0G1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmhuer/shift_invariant_dictionary_learning/blob/main/dictionarylearning_mididrums.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnTxvF-UnLg6"
      },
      "source": [
        "# Set up enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54x_9yGfkRTk"
      },
      "source": [
        "#@title Magenta & MIDI & Audio\n",
        "\n",
        "print('Installing dependencies...')\n",
        "\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -q pyfluidsynth\n",
        "!pip install -U -q magenta\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "# Allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "  \n",
        "print('Importing software libraries...')\n",
        "\n",
        "import copy, warnings, librosa, numpy as np\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "# Colab/Notebook specific stuff\n",
        "import IPython.display\n",
        "from IPython.display import Audio\n",
        "from google.colab import files\n",
        "\n",
        "# Magenta specific stuff\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "from magenta.models.music_vae import data\n",
        "import note_seq\n",
        "from note_seq import midi_synth\n",
        "from note_seq.sequences_lib import concatenate_sequences\n",
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "# Define some functions\n",
        "\n",
        "# If a sequence has notes at time before 0.0, scootch them up to 0\n",
        "def start_notes_at_0(s):\n",
        "  for n in s.notes:\n",
        "    if n.start_time < 0:\n",
        "      n.end_time -= n.start_time\n",
        "      n.start_time = 0\n",
        "  return s\n",
        "\n",
        "def play(note_sequence, sf2_path='Standard_Drum_Kit.sf2'):  \n",
        "  if sf2_path:\n",
        "    audio_seq = midi_synth.fluidsynth(start_notes_at_0(note_sequence), sample_rate=44100, sf2_path=sf2_path)\n",
        "    IPython.display.display(IPython.display.Audio(audio_seq, rate=44100))\n",
        "  else:\n",
        "    note_seq.play_sequence(start_notes_at_0(note_sequence), synth=note_seq.fluidsynth)\n",
        "\n",
        "# Some midi files come by default from different instrument channels\n",
        "# Quick and dirty way to set midi files to be recognized as drums\n",
        "def set_to_drums(ns):\n",
        "  for n in ns.notes:\n",
        "    n.instrument=9\n",
        "    n.is_drum = True\n",
        "    \n",
        "def unset_to_drums(ns):\n",
        "  for note in ns.notes:\n",
        "    note.is_drum=False\n",
        "    note.instrument=0\n",
        "  return ns\n",
        "\n",
        "# quickly change the tempo of a midi sequence and adjust all notes\n",
        "def change_tempo(note_sequence, new_tempo):\n",
        "  new_sequence = copy.deepcopy(note_sequence)\n",
        "  ratio = note_sequence.tempos[0].qpm / new_tempo\n",
        "  for note in new_sequence.notes:\n",
        "    note.start_time = note.start_time * ratio\n",
        "    note.end_time = note.end_time * ratio\n",
        "  new_sequence.tempos[0].qpm = new_tempo\n",
        "  return new_sequence\n",
        "\n",
        "def download(note_sequence, filename):\n",
        "  note_seq.sequence_proto_to_midi_file(note_sequence, filename)\n",
        "  files.download(filename)\n",
        "  \n",
        "def download_audio(audio_sequence, filename, sr):\n",
        "  librosa.output.write_wav(filename, audio_sequence, sr=sr, norm=True)\n",
        "  files.download(filename)\n",
        " \n",
        "# Load some configs to be used later\n",
        "dc_quantize = configs.CONFIG_MAP['groovae_2bar_humanize'].data_converter\n",
        "dc_tap = configs.CONFIG_MAP['groovae_2bar_tap_fixed_velocity'].data_converter\n",
        "dc_hihat = configs.CONFIG_MAP['groovae_2bar_add_closed_hh'].data_converter\n",
        "dc_4bar = configs.CONFIG_MAP['groovae_4bar'].data_converter\n",
        "\n",
        "# quick method for removing microtiming and velocity from a sequence\n",
        "def get_quantized_2bar(s, velocity=0):\n",
        "  new_s = dc_quantize.from_tensors(dc_quantize.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  if velocity != 0:\n",
        "    for n in new_s.notes:\n",
        "      n.velocity = velocity\n",
        "  return new_s\n",
        "\n",
        "# quick method for turning a drumbeat into a tapped rhythm\n",
        "def get_tapped_2bar(s, velocity=85, ride=False):\n",
        "  new_s = dc_tap.from_tensors(dc_tap.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  if velocity != 0:\n",
        "    for n in new_s.notes:\n",
        "      n.velocity = velocity\n",
        "  if ride:\n",
        "    for n in new_s.notes:\n",
        "      n.pitch = 42\n",
        "  return new_s\n",
        "\n",
        "# quick method for removing hi-hats from a sequence\n",
        "def get_hh_2bar(s):\n",
        "  new_s = dc_hihat.from_tensors(dc_hihat.to_tensors(s).inputs)[0]\n",
        "  new_s = change_tempo(new_s, s.tempos[0].qpm)\n",
        "  return new_s\n",
        "\n",
        "\n",
        "# Calculate quantization steps but do not remove microtiming\n",
        "def quantize(s, steps_per_quarter=4):\n",
        "  return note_seq.sequences_lib.quantize_note_sequence(s,steps_per_quarter)\n",
        "\n",
        "# Destructively quantize a midi sequence\n",
        "def flatten_quantization(s):\n",
        "  beat_length = 60. / s.tempos[0].qpm\n",
        "  step_length = beat_length / 4#s.quantization_info.steps_per_quarter\n",
        "  new_s = copy.deepcopy(s)\n",
        "  for note in new_s.notes:\n",
        "    note.start_time = step_length * note.quantized_start_step\n",
        "    note.end_time = step_length * note.quantized_end_step\n",
        "  return new_s\n",
        "\n",
        "# Calculate how far off the beat a note is\n",
        "def get_offset(s, note_index):\n",
        "  q_s = flatten_quantization(quantize(s))\n",
        "  true_onset = s.notes[note_index].start_time\n",
        "  quantized_onset = q_s.notes[note_index].start_time\n",
        "  diff = quantized_onset - true_onset\n",
        "  beat_length = 60. / s.tempos[0].qpm\n",
        "  step_length = beat_length / 4#q_s.quantization_info.steps_per_quarter\n",
        "  offset = diff/step_length\n",
        "  return offset\n",
        "\n",
        "def is_4_4(s):\n",
        "  ts = s.time_signatures[0]\n",
        "  return (ts.numerator == 4 and ts.denominator ==4)\n",
        "\n",
        "def preprocess_4bar(s):\n",
        "  return dc_4bar.from_tensors(dc_4bar.to_tensors(s).outputs)[0]\n",
        "\n",
        "def preprocess_2bar(s):\n",
        "  return dc_quantize.from_tensors(dc_quantize.to_tensors(s).outputs)[0]\n",
        "\n",
        "def _slerp(p0, p1, t):\n",
        "  \"\"\"Spherical linear interpolation.\"\"\"\n",
        "  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)),\n",
        "    np.squeeze(p1/np.linalg.norm(p1))))\n",
        "  so = np.sin(omega)\n",
        "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
        "\n",
        "print('Downloading drum samples...')\n",
        "# Download a drum kit for playing drum midi\n",
        "!gsutil -q -m cp gs://magentadata/soundfonts/Standard_Drum_Kit.sf2 .\n",
        "\n",
        "print(\"Download MIDI data...\")\n",
        "\n",
        "# # Load MIDI files from GMD with MIDI only (no audio) as a tf.data.Dataset\n",
        "# dataset_2bar = tfds.as_numpy(tfds.load(\n",
        "#     name=\"groove/2bar-midionly\",\n",
        "#     split=tfds.Split.VALIDATION,\n",
        "#     try_gcs=True))\n",
        "\n",
        "# dev_sequences = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_2bar]\n",
        "# _ = [set_to_drums(s) for s in dev_sequences]\n",
        "# dev_sequences = [s for s in dev_sequences if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n",
        "\n",
        "dataset_4bar = tfds.as_numpy(tfds.load(\n",
        "    name=\"groove/4bar-midionly\",\n",
        "    split=tfds.Split.VALIDATION,\n",
        "    try_gcs=True))\n",
        "\n",
        "dev_sequences_4bar = [quantize(note_seq.midi_to_note_sequence(features[\"midi\"])) for features in dataset_4bar]\n",
        "_ = [set_to_drums(s) for s in dev_sequences_4bar]\n",
        "dev_sequences_4bar = [s for s in dev_sequences_4bar if is_4_4(s) and len(s.notes) > 0 and s.notes[-1].quantized_end_step > note_seq.steps_per_bar_in_quantized_sequence(s)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkmAYGx9l0HJ"
      },
      "source": [
        "#@title Pytorch for DL\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOMZVO4pltPg"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}